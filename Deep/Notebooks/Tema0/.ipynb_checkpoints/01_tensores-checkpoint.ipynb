{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5cd21e",
   "metadata": {},
   "source": [
    "# Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7f3c6",
   "metadata": {},
   "source": [
    "PyTorch es una biblioteca y marco de trabajo de código abierto que facilita la programación de redes neuronales profundas, ofreciendo varias funciones, clases y herramientas. En particular:\n",
    "<ol>\n",
    "    <li>Definición de arreglos multidimensionales (clase <tt>Tensor</tt>) y operaciones entre ellos con soporte para GPUs y cómputo distribuido.</li>\n",
    "    <li>Diferenciación automática.</li>\n",
    "    <li>Interfaz modular con distintos niveles de abstracción para definir arquitecturas de redes neuronales y entrenarlas.</li>\n",
    "    <li>Clases y funciones para carga, generación de lotes y preprocesamiento de conjuntos de datos.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf0168",
   "metadata": {},
   "source": [
    "<img src=\"tensor1.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ea37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b9485",
   "metadata": {},
   "source": [
    "## Creación de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650ee48",
   "metadata": {},
   "source": [
    "El objeto básico de PyTorch es el tensor: un arreglo multidimensional similar al <tt>ndarray</tt> de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9c574",
   "metadata": {},
   "source": [
    "<img src = \"tensor2.jpeg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9999e",
   "metadata": {},
   "source": [
    "Podemos definir un tensor a partir de valores específicos con la función <tt>tensor()</tt>. Para un escalar (tensor de orden 0), esto sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e97fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de orden 0 (escalar): 4.0\n",
      "Tipo: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "escalar = th.tensor(4.0)\n",
    "print(f'Tensor de orden 0 (escalar): {escalar}\\nTipo: {type(escalar)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b3dfd",
   "metadata": {},
   "source": [
    "Un vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9aeb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de orden 1: tensor([2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "vector = th.tensor([2., 3., 4.])\n",
    "print(f'Tensor de orden 1: {vector}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0644c3c",
   "metadata": {},
   "source": [
    "Una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd36f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "matriz = th.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c7d34",
   "metadata": {},
   "source": [
    "Tensor de orden 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be02517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "tensor3 = th.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]], [[13,14,15,16],[17,18,19,20],[21,22,23,24]]])\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb299a3a",
   "metadata": {},
   "source": [
    "Similar a NumPy, las instancias de <tt>Tensor</tt> tienen varios atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c52f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos: torch.int64\n",
      "Número de ejes (dimensiones): 3\n",
      "Forma: torch.Size([2, 3, 4])\n",
      "Forma (otra vez): torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f'Tipo de datos: {tensor3.dtype}')\n",
    "print(f'Número de ejes (dimensiones): {tensor3.ndim}')\n",
    "print(f'Forma: {tensor3.shape}')\n",
    "print(f'Forma (otra vez): {tensor3.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1121a4",
   "metadata": {},
   "source": [
    "PyTorch infiere el tipo de datos del tensor a partir de los valores, pero también es posible especificarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a6d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos por defecto: torch.int64\n",
      "Tipo de datos especificado: torch.float64\n"
     ]
    }
   ],
   "source": [
    "vi64 = th.tensor([1,2])\n",
    "vf64 = th.tensor([1,2], dtype = th.float64)\n",
    "print(f'Tipo de datos por defecto: {vi64.dtype}')\n",
    "print(f'Tipo de datos especificado: {vf64.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f5f4d",
   "metadata": {},
   "source": [
    "Otra forma de crear un tensor es con la función <tt>zeros()</tt>, que recibe como argumento la forma del tensor y regresa un tensor de esa forma (shape) con todos los elementos iguales a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca32372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de ceros\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "ceros = th.zeros((3,4), dtype = th.float32)\n",
    "print('Matriz de ceros')\n",
    "print(ceros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8c795",
   "metadata": {},
   "source": [
    "La función <tt>ones()</tt> es similar a <tt>zeros()</tt> pero en lugar de poner todos los valores a 0 los pone a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f57a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de unos:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Tipo:\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "unos = th.ones((3,4), dtype=th.float32)\n",
    "print('Matriz de unos:')\n",
    "print(unos)\n",
    "print('Tipo:')\n",
    "print(unos.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f87220",
   "metadata": {},
   "source": [
    "De forma analógica, <tt>ones_like()</tt> es una variación de esta última función que toma la forma de otro tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0132f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de unos a partir de otro tensor: tensor([1, 1]) (torch.int64)\n"
     ]
    }
   ],
   "source": [
    "unos_l = th.ones_like(vi64)\n",
    "print(f'Matriz de unos a partir de otro tensor: {unos_l} ({unos_l.dtype})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5d953",
   "metadata": {},
   "source": [
    "PyTorch también permite crear tensores con valores muestreados. Ejemplo: uniforme en un rango [0,1) usando la función <tt>rand()</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d077fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con elementos muestreados uniformemente de [0,1):\n",
      "tensor([[0.1494, 0.4348, 0.2939],\n",
      "        [0.2312, 0.7684, 0.8483],\n",
      "        [0.1722, 0.3829, 0.2319],\n",
      "        [0.2453, 0.4092, 0.7903]])\n"
     ]
    }
   ],
   "source": [
    "unif_ten = th.rand((4,3))\n",
    "print(f'Matriz con elementos muestreados uniformemente de [0,1):\\n{unif_ten}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c850397",
   "metadata": {},
   "source": [
    "Usando los tensores generados por <mark><tt>rand</tt></mark> (y <mark><tt>rand_like</tt></mark>) es posible generar tensores con valores muestreados de manera uniforme en un rango $[a,b)$ de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e055ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con elementos muestreados uniformemente de [-5,3):\n",
      "tensor([[ 1.9092, -1.8055, -3.8583],\n",
      "        [-1.1735,  2.6927, -4.5595],\n",
      "        [-2.2645, -0.4043,  2.6320],\n",
      "        [ 2.4825, -1.4083,  1.0338]])\n"
     ]
    }
   ],
   "source": [
    "a = -5\n",
    "b = 3\n",
    "unifab_ten = th.rand((4,3))*(b-a) + a\n",
    "print(f'Matriz con elementos muestreados uniformemente de [-5,3):\\n{unifab_ten}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f7b0c",
   "metadata": {},
   "source": [
    "Alternativamente, podemos instanciar una clase <mark><tt>Tensor</tt></mark> pasando el tamaño como artumento al constructor y llamando al método <mark><tt>uniform_</tt></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8951f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1299,  1.0294, -3.0743],\n",
       "        [-3.7605, -3.2202,  1.6602],\n",
       "        [-1.1481, -1.6805, -2.3771],\n",
       "        [ 2.0695,  2.3734,  0.2925]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.Tensor(4,3).uniform_(-5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8051ceb",
   "metadata": {},
   "source": [
    "Para valores enteros muestreados uniformemente tenemos la función <mark><tt>randint</tt></mark> (y <mark><tt>randint_like</tt></mark>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e06221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con enteros muestreados uniformemente de [-5,3):\n",
      "tensor([[ 0,  1, -4],\n",
      "        [ 1,  1, -3],\n",
      "        [-2,  1, -5],\n",
      "        [ 0, -1,  2]])\n"
     ]
    }
   ],
   "source": [
    "unifint_ten = th.randint(low=-5, high=3, size=(4,3))\n",
    "print('Matriz con enteros muestreados uniformemente de [-5,3):')\n",
    "print(unifint_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36de2a0",
   "metadata": {},
   "source": [
    "De forma similar, la función <mark><tt>randn</tt></mark> genera tensores con valores muestreados de una normal con media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388a659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con elementos muestreados de normal estándar:\n",
      "tensor([[-0.1539, -0.2625, -1.0968],\n",
      "        [ 1.2534, -2.1035, -0.6110],\n",
      "        [ 0.3515,  0.1708, -1.1174],\n",
      "        [ 0.9991, -1.3011,  0.5970]])\n"
     ]
    }
   ],
   "source": [
    "randn_ten = th.randn(size=(4,3))\n",
    "print('Matriz con elementos muestreados de normal estándar:')\n",
    "print(randn_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e28e5",
   "metadata": {},
   "source": [
    "Con los tensores generados por <mark><tt>randn</tt></mark> podemos generar tensores cuyos valores sean muestreados de una normal con distinta media y desviación estándar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db96bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con elementos muestreados de normal (μ=-5, σ=10):\n",
      "tensor([[ -9.8613,  -2.9735,  -7.0926],\n",
      "        [ 11.3910, -14.1567,   7.6604],\n",
      "        [  3.1724,  -5.3693,  -4.3224],\n",
      "        [ -3.7743,  -9.9124, -32.5436]])\n"
     ]
    }
   ],
   "source": [
    "mu = -5\n",
    "std = 10\n",
    "randnms_ten = th.randn(size=(4,3))*std + mu\n",
    "print('Matriz con elementos muestreados de normal (μ=-5, σ=10):')\n",
    "print(randnms_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c45ae7",
   "metadata": {},
   "source": [
    "También podemos generar tensores con valores muestreados de una normal con media y desviación estándar arbitraria usando la función <mark><tt>normal</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2712c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con elementos muestreados de normal (μ=-5, σ=10):\n",
      "tensor([[ -7.0055,  -3.8773,  -8.8942],\n",
      "        [-10.6846, -16.9980,  -4.9416],\n",
      "        [ -0.1589,  -4.3523, -27.9076],\n",
      "        [ -1.8350,  13.9775, -18.1466]])\n"
     ]
    }
   ],
   "source": [
    "norm_ten = th.normal(size=(4,3), mean=-5, std=10)\n",
    "print('Matriz con elementos muestreados de normal (μ=-5, σ=10):')\n",
    "print(norm_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b776c4",
   "metadata": {},
   "source": [
    "Si deseamos generar tensores muestreados de una distribución multinomial, podemos usar la función <mark><tt>multinomial</tt></mark>, a la cual deben especificarse las probabilidades de cada clase como un tensor de orden 1 y el número de muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e75c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz con enteros muestreados de una multinomial:\n",
      "tensor([0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0,\n",
      "        1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1,\n",
      "        2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0,\n",
      "        1, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "cat_ten = th.multinomial(th.tensor([0.2, 0.6, 0.2]), num_samples=100, replacement=True)\n",
    "print('Matriz con enteros muestreados de una multinomial:')\n",
    "print(cat_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9d76c",
   "metadata": {},
   "source": [
    "El número de clases depende del tamaño del tensor y el argumento <mark><tt>replacement</tt></mark> define si las muestras son con o sin reemplazo (en este último caso el número de muestras debe ser menor o igual al número de clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa05f1",
   "metadata": {},
   "source": [
    "Por otra parte, la función <mark><tt>arange()</tt></mark> genera una secuencia de números (como el <mark><tt>range()</tt></mark>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2f5d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arreglo de elementos en el rango [-3, 3):\n",
      "tensor([-3.0000, -2.5000, -2.0000, -1.5000, -1.0000, -0.5000,  0.0000,  0.5000,\n",
      "         1.0000,  1.5000,  2.0000,  2.5000])\n"
     ]
    }
   ],
   "source": [
    "rango_ten1 = th.arange(start=-3, end=3, step=0.5)\n",
    "print('Arreglo de elementos en el rango [-3, 3):')\n",
    "print(rango_ten1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d8dd4",
   "metadata": {},
   "source": [
    "De manera similar, la función <mark><tt>linspace()</tt></mark> genera tensores con valores con el mismo, espaciados en un intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74e82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arreglo de elementos en el rango [-3,3]:\n",
      "tensor([-3.0000, -2.3333, -1.6667, -1.0000, -0.3333,  0.3333,  1.0000,  1.6667,\n",
      "         2.3333,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "ls_ten = th.linspace(start=-3, end=3, steps=10)\n",
    "print('Arreglo de elementos en el rango [-3,3]:')\n",
    "print(ls_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae4177",
   "metadata": {},
   "source": [
    "## Tipos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7c6bc",
   "metadata": {},
   "source": [
    "Los elementos de los tensores pueden ser de distintos tipos básicos y precisiones. Por ejemplo, flotantes de 16 bits (<mark><tt>float16</tt></mark>) o enteros sin signo de 8 bits (<mark><tt>uint8</tt></mark>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e31a46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo flotante de 64: torch.float64\n",
      "Tipo entero de 32: torch.int32\n"
     ]
    }
   ],
   "source": [
    "ten_f64 = th.arange(start=-3, end=3, step=0.5, dtype=th.float64)\n",
    "ten_i32 = th.arange(start=-3, end=3, step=1, dtype=th.int32)\n",
    "print(f'Tipo flotante de 64: {ten_f64.dtype}')\n",
    "print(f'Tipo entero de 32: {ten_i32.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f538c",
   "metadata": {},
   "source": [
    "También se pueden convertir de tipos con el método <mark><tt>type()</tt></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8811723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión de flotante de 64 a 32: torch.float32\n",
      "Conversión de entero de 32 a 64: torch.int64\n"
     ]
    }
   ],
   "source": [
    "conver_ten_f64 = ten_f64.type(th.float32)\n",
    "conver_ten_i32 = ten_i32.type(th.int64)\n",
    "print(f'Conversión de flotante de 64 a 32: {conver_ten_f64.dtype}')\n",
    "print(f'Conversión de entero de 32 a 64: {conver_ten_i32.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66b3f2",
   "metadata": {},
   "source": [
    "## Índices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da80bde",
   "metadata": {},
   "source": [
    "Los índices de los tensores siguen reglas similares a los arreglos de NumPy y las listas de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96573d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.0000,  -9.3548,  -8.7097,  -8.0645],\n",
      "        [ -7.4194,  -6.7742,  -6.1290,  -5.4839],\n",
      "        [ -4.8387,  -4.1935,  -3.5484,  -2.9032],\n",
      "        [ -2.2581,  -1.6129,  -0.9677,  -0.3226],\n",
      "        [  0.3226,   0.9677,   1.6129,   2.2581],\n",
      "        [  2.9032,   3.5484,   4.1935,   4.8387],\n",
      "        [  5.4839,   6.1290,   6.7742,   7.4194],\n",
      "        [  8.0645,   8.7097,   9.3548,  10.0000]])\n",
      "Primer renglón: [-10.        -9.354838  -8.709678  -8.064516]\n",
      "Tercer renglón: [-4.83871   -4.1935487 -3.5483873 -2.903226 ]\n",
      "Último renglón: [ 8.064516  8.709677  9.354838 10.      ]\n",
      "Primer columna: [-10.          -7.419355    -4.83871     -2.2580647    0.32258093\n",
      "   2.903226     5.483871     8.064516  ]\n",
      "Última columna: [-8.064516  -5.483871  -2.903226  -0.3225808  2.2580647  4.83871\n",
      "  7.419355  10.       ]\n"
     ]
    }
   ],
   "source": [
    "ten_ind = th.reshape(th.linspace(start=-10, end=10, steps=32), [8,4])\n",
    "print(ten_ind)\n",
    "print(f'Primer renglón: {ten_ind[0].numpy()}')\n",
    "print(f'Tercer renglón: {ten_ind[2].numpy()}')\n",
    "print(f'Último renglón: {ten_ind[-1].numpy()}')\n",
    "\n",
    "print(f'Primer columna: {ten_ind[:,0].numpy()}')\n",
    "print(f'Última columna: {ten_ind[:, -1].numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a2b87",
   "metadata": {},
   "source": [
    "También se pueden realizar <i>slices</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbcac7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los renglones:\n",
      " [[-10.          -9.354838    -8.709678    -8.064516  ]\n",
      " [ -7.419355    -6.774194    -6.129032    -5.483871  ]\n",
      " [ -4.83871     -4.1935487   -3.5483873   -2.903226  ]\n",
      " [ -2.2580647   -1.6129036   -0.9677422   -0.3225808 ]\n",
      " [  0.32258093   0.9677422    1.6129035    2.2580647 ]\n",
      " [  2.903226     3.548387     4.1935487    4.83871   ]\n",
      " [  5.483871     6.129032     6.774194     7.419355  ]\n",
      " [  8.064516     8.709677     9.354838    10.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Todos los renglones:\\n', ten_ind[:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "583c7732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renglones antes del 6\n",
      " [[-10.          -9.354838    -8.709678    -8.064516  ]\n",
      " [ -7.419355    -6.774194    -6.129032    -5.483871  ]\n",
      " [ -4.83871     -4.1935487   -3.5483873   -2.903226  ]\n",
      " [ -2.2580647   -1.6129036   -0.9677422   -0.3225808 ]\n",
      " [  0.32258093   0.9677422    1.6129035    2.2580647 ]\n",
      " [  2.903226     3.548387     4.1935487    4.83871   ]]\n"
     ]
    }
   ],
   "source": [
    "print('Renglones antes del 6\\n', ten_ind[:6].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d7092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renglones del 4 al final:\n",
      " [[ 0.32258093  0.9677422   1.6129035   2.2580647 ]\n",
      " [ 2.903226    3.548387    4.1935487   4.83871   ]\n",
      " [ 5.483871    6.129032    6.774194    7.419355  ]\n",
      " [ 8.064516    8.709677    9.354838   10.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Renglones del 4 al final:\\n', ten_ind[4:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99f6112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renglones del 3 al 5:\n",
      " [[-2.2580647  -1.6129036  -0.9677422  -0.3225808 ]\n",
      " [ 0.32258093  0.9677422   1.6129035   2.2580647 ]\n",
      " [ 2.903226    3.548387    4.1935487   4.83871   ]]\n"
     ]
    }
   ],
   "source": [
    "print('Renglones del 3 al 5:\\n', ten_ind[3:6].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df854049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cada dos renglones:\n",
      " [[-10.          -9.354838    -8.709678    -8.064516  ]\n",
      " [ -4.83871     -4.1935487   -3.5483873   -2.903226  ]\n",
      " [  0.32258093   0.9677422    1.6129035    2.2580647 ]\n",
      " [  5.483871     6.129032     6.774194     7.419355  ]]\n"
     ]
    }
   ],
   "source": [
    "print('Cada dos renglones:\\n', ten_ind[::2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d351ca",
   "metadata": {},
   "source": [
    "Un error relativamente común es:\n",
    "\n",
    "A diferencia de los arreglos de Numpy, en las instancias de Tensor no es posible que el paso de los índices sea negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40191d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[9 8 7 6 5 4 3 2 1 0]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "nparr = np.arange(start=0, stop=10, step=1)\n",
    "print(nparr)\n",
    "print(nparr[::-1])\n",
    "\n",
    "# PyTorch\n",
    "tharr = th.arange(start=0, end=10, step=1)\n",
    "print(tharr)\n",
    "# print(tharr[::-1]) Genera un: ValueError: step must be greater than zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d587d",
   "metadata": {},
   "source": [
    "Podemos iterar sobre los elementos de un tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "962e9428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0000,  -9.3548,  -8.7097,  -8.0645])\n",
      "tensor([-7.4194, -6.7742, -6.1290, -5.4839])\n",
      "tensor([-4.8387, -4.1935, -3.5484, -2.9032])\n",
      "tensor([-2.2581, -1.6129, -0.9677, -0.3226])\n",
      "tensor([0.3226, 0.9677, 1.6129, 2.2581])\n",
      "tensor([2.9032, 3.5484, 4.1935, 4.8387])\n",
      "tensor([5.4839, 6.1290, 6.7742, 7.4194])\n",
      "tensor([ 8.0645,  8.7097,  9.3548, 10.0000])\n",
      "tensor(-10.)\n",
      "tensor(-9.3548)\n",
      "tensor(-8.7097)\n",
      "tensor(-8.0645)\n",
      "tensor(-7.4194)\n",
      "tensor(-6.7742)\n",
      "tensor(-6.1290)\n",
      "tensor(-5.4839)\n",
      "tensor(-4.8387)\n",
      "tensor(-4.1935)\n",
      "tensor(-3.5484)\n",
      "tensor(-2.9032)\n",
      "tensor(-2.2581)\n",
      "tensor(-1.6129)\n",
      "tensor(-0.9677)\n",
      "tensor(-0.3226)\n",
      "tensor(0.3226)\n",
      "tensor(0.9677)\n",
      "tensor(1.6129)\n",
      "tensor(2.2581)\n",
      "tensor(2.9032)\n",
      "tensor(3.5484)\n",
      "tensor(4.1935)\n",
      "tensor(4.8387)\n",
      "tensor(5.4839)\n",
      "tensor(6.1290)\n",
      "tensor(6.7742)\n",
      "tensor(7.4194)\n",
      "tensor(8.0645)\n",
      "tensor(8.7097)\n",
      "tensor(9.3548)\n",
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "for x in ten_ind:\n",
    "    print(x)\n",
    "    \n",
    "for x in ten_ind:\n",
    "    for i in x:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c52f3",
   "metadata": {},
   "source": [
    "## Formas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9d7dc",
   "metadata": {},
   "source": [
    "La forma de los tensores puede cambiar, siempre y cuando se mantenga el mismo número de elementos totales:\n",
    "<img src=\"formas.png\"/>\n",
    "<img src=\"formas2.png\"/>\n",
    "<img src=\"formas3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04b28254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de tensor original: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "x_orig = th.arange(30)\n",
    "print(f'Forma de tensor original: {x_orig.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0463a",
   "metadata": {},
   "source": [
    "Nótese que es necesario asegurarse de que, al cambiar la forma, el número total de elementos sea el mismo. Por ejemplo, si tenemos 30 elementos, solo podemos cambiar a formas en las que el producto de todas las dimensiones sea igual a 30 ($5 \\times 6$, $6 \\times 5$, $3 \\times 10$, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f760c20",
   "metadata": {},
   "source": [
    "Para cambiar la forma de este vector usamos la función <mark><tt>reshape()</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48fc9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_forma2 = th.reshape(x_orig, [3,2,5])\n",
    "x_forma3 = th.reshape(x_orig, [3,10])\n",
    "x_forma4 = th.reshape(x_orig, [6,5])\n",
    "x_forma5 = th.reshape(x_orig, [2,3,5])\n",
    "x_forma6 = th.reshape(x_orig, [5,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcea4e5",
   "metadata": {},
   "source": [
    "Examinemos sus formas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a3df161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n",
      "torch.Size([3, 2, 5])\n",
      "torch.Size([3, 10])\n",
      "torch.Size([6, 5])\n",
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x_orig.shape)\n",
    "print(x_forma2.shape)\n",
    "print(x_forma3.shape)\n",
    "print(x_forma4.shape)\n",
    "print(x_forma5.shape)\n",
    "print(x_forma6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c341428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig, x_forma3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59f369",
   "metadata": {},
   "source": [
    "Si solo requerimos agregar una dimensión, además de la función <mark><tt>reshape</tt></mark> podemos usar <mark><tt>unsqueeze</tt></mark>, la cual toma como argumento un tensor y un eje y regresa un tensor con los mismos elementos pero con una dimensión agregada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20829e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de : torch.Size([3, 10])\n",
      "Eje 0: torch.Size([1, 3, 10])\n",
      "Eje 1: torch.Size([3, 1, 10])\n",
      "Eje 1: torch.Size([3, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'Tensor de : {x_forma3.shape}')\n",
    "print(f'Eje 0: {th.unsqueeze(x_forma3, axis=0).shape}')\n",
    "print(f'Eje 1: {th.unsqueeze(x_forma3, axis=1).shape}')\n",
    "print(f'Eje 1: {th.unsqueeze(x_forma3, axis=2).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28a8d4",
   "metadata": {},
   "source": [
    "Para quitar dimensiones de tamaño 1 se puede utilizar la función <mark><tt>squeeze</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd036b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de 4: torch.Size([1, 3, 10, 1])\n",
      "Aplicando squeeze: torch.Size([3, 10])\n",
      "Aplicando squeeze sobre eje 1: torch.Size([3, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "x_exp4 = th.unsqueeze(x_forma3, axis=2)\n",
    "x_exp4 = th.unsqueeze(x_exp4, axis=0)\n",
    "print(f'Tensor de 4: {x_exp4.shape}')\n",
    "print(f'Aplicando squeeze: {th.squeeze(x_exp4).shape}') # general\n",
    "print(f'Aplicando squeeze sobre eje 1: {th.squeeze(x_exp4, axis=0).shape}') # solo a 1 eje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e365e3",
   "metadata": {},
   "source": [
    "También podemos dividir un tensor de orden $k$ en múltiples tensores de orden $k$ con la función <mark><tt>split</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ee90e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de 3 dimensiones: torch.Size([3, 2, 5])\n",
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29]]])\n",
      "División en 3 sobre eje 0:\n",
      "(tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29]]]),)\n",
      "División en 2 sobre eje 1:\n",
      "(tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29]]]),)\n",
      "División en 3 sobre eje 2:\n",
      "(tensor([[[ 0,  1],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[10, 11],\n",
      "         [15, 16]],\n",
      "\n",
      "        [[20, 21],\n",
      "         [25, 26]]]), tensor([[[ 2,  3],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[12, 13],\n",
      "         [17, 18]],\n",
      "\n",
      "        [[22, 23],\n",
      "         [27, 28]]]), tensor([[[ 4],\n",
      "         [ 9]],\n",
      "\n",
      "        [[14],\n",
      "         [19]],\n",
      "\n",
      "        [[24],\n",
      "         [29]]]))\n"
     ]
    }
   ],
   "source": [
    "print(f'Tensor de 3 dimensiones: {x_forma2.shape}')\n",
    "print(x_forma2)\n",
    "print(f'División en 3 sobre eje 0:\\n{th.split(x_forma2, split_size_or_sections=3, dim=0)}')\n",
    "print(f'División en 2 sobre eje 1:\\n{th.split(x_forma2, split_size_or_sections=2, dim=1)}')\n",
    "print(f'División en 3 sobre eje 2:\\n{th.split(x_forma2, split_size_or_sections=[2,2,1], dim=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f014192",
   "metadata": {},
   "source": [
    "Cuando redimensionamos con <mark><tt>reshape</tt></mark> o asignamos un tensor a otro, no se está creando una copia del tensor original en memoria, sino que solo se modifica la cabecera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed35c5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " tensor([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " tensor([[[-1,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9]],\n",
       " \n",
       "         [[10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig_igual = x_orig\n",
    "x_orig[0] = -1\n",
    "x_orig, x_orig_igual, x_forma2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be18a29",
   "metadata": {},
   "source": [
    "Para crear una copia de los datos es necesario usar el método <mark><tt>clone()</tt></mark> o <mark><tt>deepcopy()</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e64ec6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9999,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "           12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "           24,   25,   26,   27,   28,   29]),\n",
       " tensor([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " tensor([[[9999,    1,    2,    3,    4],\n",
       "          [   5,    6,    7,    8,    9]],\n",
       " \n",
       "         [[  10,   11,   12,   13,   14],\n",
       "          [  15,   16,   17,   18,   19]],\n",
       " \n",
       "         [[  20,   21,   22,   23,   24],\n",
       "          [  25,   26,   27,   28,   29]]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig_clone = x_orig.clone()\n",
    "x_orig[0] = 9999\n",
    "x_orig, x_orig_clone, x_forma2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a45d46",
   "metadata": {},
   "source": [
    "## PyTorch y NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ef681",
   "metadata": {},
   "source": [
    "Los tensores de PyTorch se pueden convertir a arreglos de NumPy y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e04f23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "nparr = np.ones([2,5])\n",
    "print(nparr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896f13b",
   "metadata": {},
   "source": [
    "De arreglo de Numpy a Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28b9d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tharr = th.tensor(nparr)\n",
    "print(tharr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2424fa",
   "metadata": {},
   "source": [
    "De tensor a arreglo de Numpy con método <mark><tt>numpy()</tt></mark> de cualquier instancia de Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eb27860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(tharr.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cadeff",
   "metadata": {},
   "source": [
    "## Operaciones básicas\n",
    "\n",
    "PyTorch cuenta con operadores y funciones básicas para los tensores, similares a las de NumPy, entre ellas, operadores elemento a elemento, multiplicación por tensores, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf48a71",
   "metadata": {},
   "source": [
    "### Elemento a elemento\n",
    "\n",
    "Estas operaciones se realizan entre dos tensores que tienen la misma forma. El resultado es un tensor con la misma forma que la de los operandos, cuyos elementos se obtienen al aplicar la operación especificada entre cada elemento de un tensor y el correspondiente elemento del otro tensor. Estas operaciones pueden ser suma, resta, división y multiplicación, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06101884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1., 2., 3.]])\n",
      "y = tensor([[3., 4., 5.]])\n",
      "10*x = tensor([[10., 20., 30.]])\n",
      "x+y = tensor([[4., 6., 8.]])\n",
      "x-y = tensor([[-2., -2., -2.]])\n",
      "x*y = tensor([[ 3.,  8., 15.]])\n",
      "x/y = tensor([[0.3333, 0.5000, 0.6000]])\n",
      "x^y = tensor([[  1.,  16., 243.]])\n",
      "x^2 = tensor([[1., 4., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = th.tensor([[1.,2.,3.]])\n",
    "y = th.tensor([[3.,4.,5.]])\n",
    "\n",
    "print(f'x = {x}')\n",
    "print(f'y = {y}')\n",
    "print(f'10*x = {10*x}')\n",
    "print(f'x+y = {x+y}')\n",
    "print(f'x-y = {x-y}')\n",
    "print(f'x*y = {x*y}')\n",
    "print(f'x/y = {x/y}')\n",
    "print(f'x^y = {x**y}')\n",
    "print(f'x^2 = {x**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c04931",
   "metadata": {},
   "source": [
    "### Transpuesta, producto y concatenación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71627463",
   "metadata": {},
   "source": [
    "Es posible obtener la transpuesta de una matriz usando la función <mark><tt>transpose</tt></mark> (como argumentos se ponen los índices de los ejes en el orden deseado) o el método <mark><tt>.T</tt></mark> de cualquier instancia de Tensor. Además, podemos calcular el producto de dos vectores, dos matrices o un vector y una matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1ee5891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.]]),\n",
       " tensor([[1.],\n",
       "         [2.],\n",
       "         [3.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.transpose(x, 1,0), x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75bee43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpuesta de x:\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "Transpuesta de y:\n",
      "tensor([[3.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "Transpuesta de M1:\n",
      "tensor([[0.1904, 0.3489, 0.1500, 0.9651],\n",
      "        [0.5507, 0.4595, 0.7970, 0.5548],\n",
      "        [0.5408, 0.3020, 0.9977, 0.3406]])\n",
      "Transpuesta de M2:\n",
      "tensor([[0.6218, 0.0081, 0.0830],\n",
      "        [0.7052, 0.3557, 0.1239]])\n"
     ]
    }
   ],
   "source": [
    "# Generamos 2 matrices aleatorias\n",
    "M1 = th.rand((4,3))\n",
    "M2 = th.rand((3,2))\n",
    "\n",
    "print(f'Transpuesta de x:\\n{th.transpose(x,1,0)}')\n",
    "print(f'Transpuesta de y:\\n{y.T}')\n",
    "print(f'Transpuesta de M1:\\n{th.transpose(M1, 1,0)}')\n",
    "print(f'Transpuesta de M2:\\n{M2.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59bba83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26.]])\n",
      "tensor([[ 3.,  4.,  5.],\n",
      "        [ 6.,  8., 10.],\n",
      "        [ 9., 12., 15.]])\n",
      "tensor([[0.1677, 0.3972],\n",
      "        [0.2457, 0.4470],\n",
      "        [0.1825, 0.5129],\n",
      "        [0.6328, 0.9202]])\n"
     ]
    }
   ],
   "source": [
    "print(x @ y.T)\n",
    "print(x.T @ y)\n",
    "print(M1 @ M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98022fd0",
   "metadata": {},
   "source": [
    "También podemos concatenar una lista de tensores (primer argumento) sobre un eje específico (argumento <tt>axis</tt>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30659cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([[1., 2., 3., 3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "print(th.concat([x,y], axis = 0))\n",
    "print(th.concat([x,y], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8521f",
   "metadata": {},
   "source": [
    "De forma similar, es posible apilar tensores sobre un eje usando la función <mark><tt>stack</tt></mark> (el tensor resultado es un orden mayor al de los tensores de argumento, los cuales tienen la misma forma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7a31201",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = th.rand([5])\n",
    "v2 = th.rand([5])\n",
    "v3 = th.rand([5])\n",
    "\n",
    "M1 = th.rand([2,3])\n",
    "M2 = th.rand([2,3])\n",
    "M3 = th.rand([2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d5940",
   "metadata": {},
   "source": [
    "Apilado de vectores sobre eje 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "673d0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5096, 0.3256, 0.7315, 0.8188, 0.9406],\n",
      "        [0.5628, 0.8613, 0.6529, 0.5078, 0.4326],\n",
      "        [0.2122, 0.7992, 0.3311, 0.5386, 0.8731]])\n"
     ]
    }
   ],
   "source": [
    "print(th.stack([v1,v2,v3], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379d055",
   "metadata": {},
   "source": [
    "Apilado de vectores sobre eje 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55d13d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5096, 0.5628, 0.2122],\n",
      "        [0.3256, 0.8613, 0.7992],\n",
      "        [0.7315, 0.6529, 0.3311],\n",
      "        [0.8188, 0.5078, 0.5386],\n",
      "        [0.9406, 0.4326, 0.8731]])\n"
     ]
    }
   ],
   "source": [
    "print(th.stack([v1,v2,v3], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63991289",
   "metadata": {},
   "source": [
    "Apilado de matrices sobre eje 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a924f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5116, 0.9459, 0.3680],\n",
      "         [0.9438, 0.3936, 0.6414]],\n",
      "\n",
      "        [[0.9362, 0.5160, 0.6126],\n",
      "         [0.5732, 0.3530, 0.4958]],\n",
      "\n",
      "        [[0.5175, 0.5411, 0.1262],\n",
      "         [0.4073, 0.3101, 0.4805]]])\n"
     ]
    }
   ],
   "source": [
    "print(th.stack([M1,M2,M3], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3088836",
   "metadata": {},
   "source": [
    "Apilado de matrices sobre eje 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26497675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5116, 0.9459, 0.3680],\n",
      "         [0.9362, 0.5160, 0.6126],\n",
      "         [0.5175, 0.5411, 0.1262]],\n",
      "\n",
      "        [[0.9438, 0.3936, 0.6414],\n",
      "         [0.5732, 0.3530, 0.4958],\n",
      "         [0.4073, 0.3101, 0.4805]]])\n"
     ]
    }
   ],
   "source": [
    "print(th.stack([M1,M2,M3], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f51401",
   "metadata": {},
   "source": [
    "Apilado de matrices sobre eje 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "953d6383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5116, 0.9362, 0.5175],\n",
      "         [0.9459, 0.5160, 0.5411],\n",
      "         [0.3680, 0.6126, 0.1262]],\n",
      "\n",
      "        [[0.9438, 0.5732, 0.4073],\n",
      "         [0.3936, 0.3530, 0.3101],\n",
      "         [0.6414, 0.4958, 0.4805]]])\n"
     ]
    }
   ],
   "source": [
    "print(th.stack([M1,M2,M3], axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceecbcf6",
   "metadata": {},
   "source": [
    "## Reducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bce25d",
   "metadata": {},
   "source": [
    "También se puede reducir un eje de un tensor con distintas funciones (y métodos equivalentes), tales como suma (<mark><tt>sum</tt></mark>), producto (<mark><tt>prod</tt></mark>) y promedio (<mark><tt>mean</tt></mark>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6db6a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1461, 0.6899, 0.2166, 0.0384, 0.4060, 0.6727, 0.6024, 0.4661, 0.6135,\n",
      "         0.8635],\n",
      "        [0.4826, 0.9716, 0.3192, 0.2989, 0.3466, 0.4839, 0.1240, 0.7358, 0.5389,\n",
      "         0.9541],\n",
      "        [0.2622, 0.7569, 0.7454, 0.9654, 0.2569, 0.9789, 0.3016, 0.0353, 0.8837,\n",
      "         0.7775]])\n",
      "max tensor(0.9789)\n",
      "min tensor(0.0353)\n",
      "argmax tensor(25)\n",
      "argmin tensor(27)\n",
      "mean tensor(0.5312)\n",
      "sum tensor(15.9347)\n",
      "prod tensor(3.1546e-12)\n"
     ]
    }
   ],
   "source": [
    "x_reduction = th.rand([3,10])\n",
    "\n",
    "print(x_reduction)\n",
    "print('max', th.max(x_reduction))\n",
    "print('min', th.min(x_reduction))\n",
    "print('argmax', th.argmax(x_reduction))\n",
    "print('argmin', th.argmin(x_reduction))\n",
    "print('mean', th.mean(x_reduction))\n",
    "print('sum', th.sum(x_reduction))\n",
    "print('prod', th.prod(x_reduction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd4a31",
   "metadata": {},
   "source": [
    "Es posible especificar un eje donde se desea realizar la reducción, para las funciones <mark><tt>min</tt></mark> y <mark><tt>max</tt></mark> se devuelven un par de tensores: el primero es el de valores mínimos y el segundo es el de los índices de estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "428f293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1461, 0.6899, 0.2166, 0.0384, 0.4060, 0.6727, 0.6024, 0.4661, 0.6135,\n",
      "         0.8635],\n",
      "        [0.4826, 0.9716, 0.3192, 0.2989, 0.3466, 0.4839, 0.1240, 0.7358, 0.5389,\n",
      "         0.9541],\n",
      "        [0.2622, 0.7569, 0.7454, 0.9654, 0.2569, 0.9789, 0.3016, 0.0353, 0.8837,\n",
      "         0.7775]])\n",
      "max torch.return_types.max(\n",
      "values=tensor([0.4826, 0.9716, 0.7454, 0.9654, 0.4060, 0.9789, 0.6024, 0.7358, 0.8837,\n",
      "        0.9541]),\n",
      "indices=tensor([1, 1, 2, 2, 0, 2, 0, 1, 2, 1]))\n",
      "min torch.return_types.min(\n",
      "values=tensor([0.1461, 0.6899, 0.2166, 0.0384, 0.2569, 0.4839, 0.1240, 0.0353, 0.5389,\n",
      "        0.7775]),\n",
      "indices=tensor([0, 0, 0, 0, 2, 1, 1, 2, 1, 2]))\n",
      "argmax tensor([1, 1, 2, 2, 0, 2, 0, 1, 2, 1])\n",
      "argmin tensor([0, 0, 0, 0, 2, 1, 1, 2, 1, 2])\n",
      "mean tensor([0.2970, 0.8061, 0.4271, 0.4343, 0.3365, 0.7118, 0.3427, 0.4124, 0.6787,\n",
      "        0.8650])\n",
      "sum tensor([0.8910, 2.4184, 1.2813, 1.3028, 1.0095, 2.1354, 1.0280, 1.2373, 2.0361,\n",
      "        2.5951])\n",
      "prod tensor([0.0185, 0.5073, 0.0515, 0.0111, 0.0361, 0.3186, 0.0225, 0.0121, 0.2921,\n",
      "        0.6405])\n"
     ]
    }
   ],
   "source": [
    "print(x_reduction)\n",
    "print('max', th.max(x_reduction, axis=0))\n",
    "print('min', th.min(x_reduction, axis=0))\n",
    "print('argmax', th.argmax(x_reduction, axis=0))\n",
    "print('argmin', th.argmin(x_reduction, axis=0))\n",
    "print('mean', th.mean(x_reduction, axis=0))\n",
    "print('sum', th.sum(x_reduction, axis=0))\n",
    "print('prod', th.prod(x_reduction, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959006fa",
   "metadata": {},
   "source": [
    "Para el eje 1 del mismo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "808f5e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1461, 0.6899, 0.2166, 0.0384, 0.4060, 0.6727, 0.6024, 0.4661, 0.6135,\n",
      "         0.8635],\n",
      "        [0.4826, 0.9716, 0.3192, 0.2989, 0.3466, 0.4839, 0.1240, 0.7358, 0.5389,\n",
      "         0.9541],\n",
      "        [0.2622, 0.7569, 0.7454, 0.9654, 0.2569, 0.9789, 0.3016, 0.0353, 0.8837,\n",
      "         0.7775]])\n",
      "max torch.return_types.max(\n",
      "values=tensor([0.8635, 0.9716, 0.9789]),\n",
      "indices=tensor([9, 1, 5]))\n",
      "min torch.return_types.min(\n",
      "values=tensor([0.0384, 0.1240, 0.0353]),\n",
      "indices=tensor([3, 6, 7]))\n",
      "argmax tensor([9, 1, 5])\n",
      "argmin tensor([3, 6, 7])\n",
      "mean tensor([0.4715, 0.5256, 0.5964])\n",
      "sum tensor([4.7152, 5.2556, 5.9639])\n",
      "prod tensor([3.4092e-05, 3.5201e-04, 2.6287e-04])\n"
     ]
    }
   ],
   "source": [
    "print(x_reduction)\n",
    "print('max', th.max(x_reduction, axis=1))\n",
    "print('min', th.min(x_reduction, axis=1))\n",
    "print('argmax', th.argmax(x_reduction, axis=1))\n",
    "print('argmin', th.argmin(x_reduction, axis=1))\n",
    "print('mean', th.mean(x_reduction, axis=1))\n",
    "print('sum', th.sum(x_reduction, axis=1))\n",
    "print('prod', th.prod(x_reduction, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffe927",
   "metadata": {},
   "source": [
    "Por otro lado, tenemos la función <mark><tt>sort</tt></mark> que ordena un tensor. Al igual que <mark><tt>min</tt></mark> y <mark><tt>max</tt></mark>, cuando se especifica un eje, <mark><tt>sort</tt></mark> regresa tanto el tensor de valores como el tensor de índices. Si solo requerimos los índices, podemos usar la función <mark><tt>argsort</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb9f4bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor desordenado: tensor([0.5184, 0.2283, 0.0335, 0.3416, 0.5336, 0.1033, 0.0916, 0.1749, 0.5613,\n",
      "        0.6811, 0.6372, 0.6118])\n",
      "Tensor de 3x4: tensor([[0.5184, 0.2283, 0.0335, 0.3416],\n",
      "        [0.5336, 0.1033, 0.0916, 0.1749],\n",
      "        [0.5613, 0.6811, 0.6372, 0.6118]])\n",
      "Tensor de orden 1 de menor a mayor: torch.return_types.sort(\n",
      "values=tensor([0.0335, 0.0916, 0.1033, 0.1749, 0.2283, 0.3416, 0.5184, 0.5336, 0.5613,\n",
      "        0.6118, 0.6372, 0.6811]),\n",
      "indices=tensor([ 2,  6,  5,  7,  1,  3,  0,  4,  8, 11, 10,  9]))\n",
      "Tensor de orden 1 de mayor a menor: torch.return_types.sort(\n",
      "values=tensor([0.6811, 0.6372, 0.6118, 0.5613, 0.5336, 0.5184, 0.3416, 0.2283, 0.1749,\n",
      "        0.1033, 0.0916, 0.0335]),\n",
      "indices=tensor([ 9, 10, 11,  8,  4,  0,  3,  1,  7,  5,  6,  2]))\n",
      "Tensor de orden 2 de menor a mayor sobre eje 0: torch.return_types.sort(\n",
      "values=tensor([[0.5184, 0.1033, 0.0335, 0.1749],\n",
      "        [0.5336, 0.2283, 0.0916, 0.3416],\n",
      "        [0.5613, 0.6811, 0.6372, 0.6118]]),\n",
      "indices=tensor([[0, 1, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [2, 2, 2, 2]]))\n",
      "Tensor de orden 2 de menor a mayor sobre eje 1: torch.return_types.sort(\n",
      "values=tensor([[0.0335, 0.2283, 0.3416, 0.5184],\n",
      "        [0.0916, 0.1033, 0.1749, 0.5336],\n",
      "        [0.5613, 0.6118, 0.6372, 0.6811]]),\n",
      "indices=tensor([[2, 1, 3, 0],\n",
      "        [2, 1, 3, 0],\n",
      "        [0, 3, 2, 1]]))\n",
      "Índices de menor a mayor: tensor([ 2,  6,  5,  7,  1,  3,  0,  4,  8, 11, 10,  9])\n",
      "Índices de mayor a menor: tensor([ 9, 10, 11,  8,  4,  0,  3,  1,  7,  5,  6,  2])\n",
      "Índices de eje 0 de menor a mayor: tensor([[0, 1, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [2, 2, 2, 2]])\n",
      "Índices de eje 1 de menor a mayor: tensor([[2, 1, 3, 0],\n",
      "        [2, 1, 3, 0],\n",
      "        [0, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "desord = th.rand([12])\n",
    "print('Tensor desordenado:', desord)\n",
    "print('Tensor de 3x4:', desord.reshape((3,4)))\n",
    "\n",
    "print('Tensor de orden 1 de menor a mayor:', th.sort(desord, descending=False))\n",
    "print('Tensor de orden 1 de mayor a menor:', th.sort(desord, descending=True))\n",
    "\n",
    "print('Tensor de orden 2 de menor a mayor sobre eje 0:', th.sort(th.reshape(desord, (3,4)), descending=False, axis=0))\n",
    "print('Tensor de orden 2 de menor a mayor sobre eje 1:', th.sort(th.reshape(desord, (3,4)), descending=False, axis=1))\n",
    "\n",
    "print('Índices de menor a mayor:', th.argsort(desord, descending=False))\n",
    "print('Índices de mayor a menor:', th.argsort(desord, descending=True))\n",
    "print('Índices de eje 0 de menor a mayor:', th.argsort(desord.reshape((3,4)), descending=False, axis=0))\n",
    "print('Índices de eje 1 de menor a mayor:', th.argsort(desord.reshape((3,4)), descending=False, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d14408",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30333fc4",
   "metadata": {},
   "source": [
    "En muchos casos, el uso de GPUs reduce significativamente el tiempo de entrenamiento de los modelos basados en redes neuronales profundas. Por lo mismo, los marcos de trabajo como PyTorch permiten crear o copiar tensores y ejecutar las operaciones tensoriales en uno o más CPUs/GPUs e incluso en distintas computadoras. Además, ofrecen herramientas para controlar de manera flexible dónde se crea o copia cada tensor y dónde se ejecuta cada operación. Por ello, cada instancia de la clase <mark><tt>Tensor</tt></mark> cuenta con el elemento <mark><tt>.device</tt></mark> que indica el dispositivo en el que se encuentra almacenado. Por defecto, si hay al menos uno disponible, los tensores se crean en el GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3ab7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94aea270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "xcpu = th.rand((100,100))\n",
    "print(xcpu.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b02991",
   "metadata": {},
   "source": [
    "Podemos especificar explícitamente dónde queremos crear una instancia de Tensor usando el argumento <mark><tt>device</tt></mark> que tienen muchas funciones de PyTorch. Por ejemplo, si queremos crear el tensor en GPU pasamos la cadena <mark><tt>cuda</tt></mark> o <mark><tt>cuda:0</tt></mark>, donde el valor después de los dos puntos en esta última forma especifica el índice del GPU (es distinto de 0 cuando tenemos múltiplies GPUs disponibles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7fd4ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xgpu \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m xgpu\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "xgpu = th.rand((100,100), device='cuda:0')\n",
    "xgpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db33143",
   "metadata": {},
   "source": [
    "Las operaciones que se realicen con estos tensores se correrán en el GPU y los tensores resultantes estarán en este mismo dispositivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ygpu = th.rand((100, 100), device='cuda:0')\n",
    "(xgpu + ygpu).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318c79b",
   "metadata": {},
   "source": [
    "Sin embargo, cuando realizamos una operación con tensores que se encuentran en dispositivos distintos, PyTorch lanza un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8157fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genera un error porque se quiere realizar una operación con tensores que están en distintos dispositivos\n",
    "# xgpu1 + xcpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d187b9",
   "metadata": {},
   "source": [
    "Por lo tanto, para poder realizar esta operación es necesario transferir uno de los tensores a otro dispositivo. En PyTorch esto lo llevamos a cabo con el método <mark><tt>to</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcpugpu = xcpu.to('cuda:0')\n",
    "(xgpu + xcpugpu).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ecabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcpugpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff9784",
   "metadata": {},
   "source": [
    "Para saber si algún GPU está disponible, contamos con la función <mark><tt>is_available</tt></mark> del módulo de <mark><tt>cuda</tt></mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7c3e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ecfc4",
   "metadata": {},
   "source": [
    "Comparemos ahora los tiempos de ejecución en un CPU y un GPU de una multiplicación de dos matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "disp='cpu'\n",
    "res = th.rand((10000, 10000), device=disp) @ th.rand((10000,10000), device=disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37151d3",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Calcula y despliega el producto de cada matriz de $400 \\times 1000$ en un tensor aleatorio $A$ de tamaño $500 \\times 400 \\times 1000$ con la transpuesta de un tensor aleatorio $B$ de tamaño $200 \\times 1000$. Concatena el resultado a un tensor aleatorio $C$ con el mismo número de columnas que el resultado de la operación anterior. Compara los tiempos de ejecución de esta operación en GPU y CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8147f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
