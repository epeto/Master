{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Deterministic Policy Gradient\n",
        "\n",
        "En este notebook se implementará el algoritmo DDPG y se aplicará a un ambiente de gymnasium."
      ],
      "metadata": {
        "id": "8-R7FEt9abkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se importarán las bibliotecas necesarias."
      ],
      "metadata": {
        "id": "DYJQN_UsbvMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[mujoco]"
      ],
      "metadata": {
        "id": "MMoYfZ9_UF5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8941b846-0649-4630-9539-9da9dc3e617a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[mujoco] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (0.0.8)\n",
            "Requirement already satisfied: mujoco==2.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (2.2.0)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (2.31.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[mujoco]) (2.6.3)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[mujoco]) (3.1.7)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gym[mujoco]) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install glfw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIzIKWTSsjF_",
        "outputId": "081d151e-ccc7-485d-a656-d0fea493c5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (2.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mujoco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGb1qzrbs0UQ",
        "outputId": "b6c78b00-dae3-4684-c4a3-17b7a4205f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mujoco in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.23.5)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import ptan\n",
        "except:\n",
        "    !pip install ptan\n",
        "    import ptan"
      ],
      "metadata": {
        "id": "LJZ2Bslx97Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from tensorboardX import SummaryWriter\n",
        "except:\n",
        "    !pip install tensorboardX\n",
        "    from tensorboardX import SummaryWriter"
      ],
      "metadata": {
        "id": "Ae-x_WskLzku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "import gym\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jl_qsJAab0Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La biblioteca PTAN\n",
        "\n",
        "Para simplificar la implementación, se usará la biblioteca PTAN (Pytorch AgentNet), la cual es una caja de herramientas de aprendizaje por refuerzo.\n",
        "\n",
        "Para esta implementación se usará la plantilla para el agente `BaseAgent`. Para el buffer de recuerdos se usará la clase `ExperienceReplayBuffer`."
      ],
      "metadata": {
        "id": "laBnPE1Eg716"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El actor\n",
        "\n",
        "Se creará la clase para la red neuronal relacionada con la política, a la cual se le llama *actor*."
      ],
      "metadata": {
        "id": "aZ1sPjmrdmZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, obs_size, act_size):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            #nn.BatchNorm1d(obs_size),\n",
        "            nn.Linear(obs_size, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, act_size),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # en el caso de cartpole de Mujoco, la señal está en el rango [-3,3]\n",
        "        # por eso se multiplica el resultado de tanh por 3\n",
        "        return 3*self.net(x)"
      ],
      "metadata": {
        "id": "onybJHIheYNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El crítico\n",
        "\n",
        "Ahora se creará la clase para la red neuronal relacionada con la función de acción-valor ($Q(s, a)$).\n",
        "\n",
        "Las acciones no se incluyen hasta la segunda capa de $Q$."
      ],
      "metadata": {
        "id": "3TzW6hQf6oak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, obs_size, act_size):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.obs_net = nn.Sequential(\n",
        "            nn.Linear(obs_size, 400),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.out_net = nn.Sequential(\n",
        "            nn.Linear(400 + act_size, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, 1))\n",
        "\n",
        "    def forward(self, x, a):\n",
        "        obs = self.obs_net(x)\n",
        "        return self.out_net(torch.cat([obs, a], dim=1))"
      ],
      "metadata": {
        "id": "yf6m06Lf64lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El agente\n",
        "\n",
        "Ahora se creará la clase para el agente de aprendizaje por refuerzo.\n",
        "\n",
        "Para la exploración se usa ruido correlacionado. Se usa el proceso de *Ornstein-Uhlenbeck* con $\\theta = 0.15$ y $\\sigma = 0.2$, con una media de 0."
      ],
      "metadata": {
        "id": "Ciej-NBx-J8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(ptan.agent.BaseAgent):\n",
        "    def __init__(self, net, device='cpu', ou_enabled=True, ou_mu=0.0, ou_teta=0.15, ou_sigma=0.2, ou_epsilon=1.0):\n",
        "        self.net = net\n",
        "        self.device = device\n",
        "        self.ou_enabled = ou_enabled\n",
        "        self.ou_mu = ou_mu\n",
        "        self.ou_teta = ou_teta\n",
        "        self.ou_sigma = ou_sigma\n",
        "        self.ou_epsilon = ou_epsilon\n",
        "\n",
        "    def initial_state(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, states, agent_states):\n",
        "        states_v = ptan.agent.float32_preprocessor(states)\n",
        "        states_v = states_v.to(self.device)\n",
        "        mu_v = self.net(states_v)\n",
        "        actions = mu_v.data.cpu().numpy()\n",
        "\n",
        "        if self.ou_enabled and self.ou_epsilon > 0:\n",
        "            new_a_states = []\n",
        "            for a_state, action in zip(agent_states, actions):\n",
        "                if a_state is None:\n",
        "                    a_state = np.zeros(shape=action.shape, dtype=np.float32)\n",
        "                a_state += self.ou_teta*(self.ou_mu - a_state)\n",
        "                a_state += self.ou_sigma*np.random.normal(size=action.shape)\n",
        "                action += self.ou_epsilon*a_state\n",
        "                new_a_states.append(a_state)\n",
        "        else:\n",
        "            new_a_states = agent_states\n",
        "        actions = np.clip(actions, -1, 1)\n",
        "        return actions, new_a_states"
      ],
      "metadata": {
        "id": "EWAvFae2-QUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento del lote\n",
        "\n",
        "Se usará una función para desempacar el lote."
      ],
      "metadata": {
        "id": "Y2WBsgcr44kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unpack_batch(batch, device=\"cpu\"):\n",
        "    states, actions, rewards, dones, last_states = [], [], [], [], []\n",
        "    for exp in batch:\n",
        "        states.append(exp.state)\n",
        "        actions.append(exp.action)\n",
        "        rewards.append(exp.reward)\n",
        "        dones.append(exp.last_state is None)\n",
        "        if exp.last_state is None:\n",
        "            last_states.append(exp.state)\n",
        "        else:\n",
        "            last_states.append(exp.last_state)\n",
        "    states_v = ptan.agent.float32_preprocessor(states).to(device)\n",
        "    actions_v = ptan.agent.float32_preprocessor(actions).to(device)\n",
        "    rewards_v = ptan.agent.float32_preprocessor(rewards).to(device)\n",
        "    last_states_v = ptan.agent.float32_preprocessor(last_states).to(device)\n",
        "    dones_t = torch.BoolTensor(dones).to(device)\n",
        "    return states_v, actions_v, rewards_v, dones_t, last_states_v"
      ],
      "metadata": {
        "id": "55_qEI6T5FGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fase de entrenamiento\n",
        "\n",
        "Primero se definirán los parámetros para la fase de entrenamiento."
      ],
      "metadata": {
        "id": "rfLZiGjiDCnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ENV_ID = 'Pendulum-v1'\n",
        "ENV_ID = 'InvertedPendulum-v4'\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE_ACTOR = 1e-4\n",
        "LEARNING_RATE_CRITIC = 1e-3\n",
        "REPLAY_SIZE = 100000\n",
        "REPLAY_INITIAL = 1000\n",
        "TEST_ITERS = 1000\n",
        "MAX_EPOCAS = 100000 # cambiar dependiendo del tiempo que tarda"
      ],
      "metadata": {
        "id": "nWlQstDPDJbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_net(net, env, count=10, device='cpu'):\n",
        "    rewards = 0.0\n",
        "    steps = 0\n",
        "    for _ in range(count):\n",
        "        obs = env.reset()\n",
        "        terminado = False\n",
        "        while not terminado:\n",
        "            obs_v = ptan.agent.float32_preprocessor([obs]).to(device)\n",
        "            mu_v = net(obs_v)\n",
        "            action = mu_v.squeeze(dim=0).data.cpu().numpy()\n",
        "            action = np.clip(action, -3, 3) # acotar la acción entre -3 y 3\n",
        "            obs, reward, done, truncated = env.step(action)\n",
        "            rewards += reward\n",
        "            steps += 1\n",
        "            if done or truncated:\n",
        "                terminado = True\n",
        "    return rewards/count, steps/count"
      ],
      "metadata": {
        "id": "JzYBkF9jVPNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entrenamiento():\n",
        "    recompensas_ent = []\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    save_path = os.path.join(\"saves\", \"ddpg-\" + 'pendulum')\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    env = gym.make(ENV_ID)\n",
        "    test_env = gym.make(ENV_ID)\n",
        "\n",
        "    act_net = Actor(env.observation_space.shape[0], env.action_space.shape[0]).to(device)\n",
        "    crt_net = Critic(env.observation_space.shape[0], env.action_space.shape[0]).to(device)\n",
        "    # Target networks\n",
        "    tgt_act_net = ptan.agent.TargetNet(act_net)\n",
        "    tgt_crt_net = ptan.agent.TargetNet(crt_net)\n",
        "\n",
        "    writer = SummaryWriter(comment='-ddpg_'+'pendulum')\n",
        "    agent = Agent(act_net, device = device)\n",
        "    exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=GAMMA, steps_count=1)\n",
        "    buffer = ptan.experience.ExperienceReplayBuffer(exp_source, buffer_size=REPLAY_SIZE)\n",
        "    act_opt = optim.Adam(act_net.parameters(), lr=LEARNING_RATE_ACTOR)\n",
        "    crt_opt = optim.Adam(crt_net.parameters(), lr=LEARNING_RATE_CRITIC)\n",
        "\n",
        "    frame_idx = 0\n",
        "    best_reward = None\n",
        "    with ptan.common.utils.RewardTracker(writer) as tracker:\n",
        "        with ptan.common.utils.TBMeanTracker(writer, batch_size=10) as tb_tracker:\n",
        "            for _ in range(MAX_EPOCAS):\n",
        "                frame_idx += 1\n",
        "                buffer.populate(1)\n",
        "                rewards_steps = exp_source.pop_rewards_steps()\n",
        "                if rewards_steps:\n",
        "                    rewards, steps = zip(*rewards_steps)\n",
        "                    tb_tracker.track('episode_steps', steps[0], frame_idx)\n",
        "                    tracker.reward(rewards[0], frame_idx)\n",
        "\n",
        "                if len(buffer) < REPLAY_INITIAL:\n",
        "                    continue\n",
        "\n",
        "                batch = buffer.sample(BATCH_SIZE)\n",
        "                states_v, actions_v, rewards_v, dones_mask, last_states_v = unpack_batch(batch, device)\n",
        "\n",
        "                # train critic\n",
        "                crt_opt.zero_grad()\n",
        "                q_v = crt_net(states_v, actions_v)\n",
        "                last_act_v = tgt_act_net.target_model(last_states_v)\n",
        "                q_last_v = tgt_crt_net.target_model(last_states_v, last_act_v)\n",
        "                q_last_v[dones_mask] = 0.0\n",
        "                q_ref_v = rewards_v.unsqueeze(dim=-1) + q_last_v * GAMMA\n",
        "                critic_loss_v = F.mse_loss(q_v, q_ref_v.detach())\n",
        "                critic_loss_v.backward()\n",
        "                crt_opt.step()\n",
        "                tb_tracker.track(\"loss_critic\", critic_loss_v, frame_idx)\n",
        "                tb_tracker.track(\"critic_ref\", q_ref_v.mean(), frame_idx)\n",
        "\n",
        "                # train actor\n",
        "                act_opt.zero_grad()\n",
        "                cur_actions_v = act_net(states_v)\n",
        "                actor_loss_v = -crt_net(states_v, cur_actions_v)\n",
        "                actor_loss_v = actor_loss_v.mean()\n",
        "                actor_loss_v.backward()\n",
        "                act_opt.step()\n",
        "                tb_tracker.track(\"loss_actor\", actor_loss_v, frame_idx)\n",
        "                tgt_act_net.alpha_sync(alpha=1 - 1e-3)\n",
        "                tgt_crt_net.alpha_sync(alpha=1 - 1e-3)\n",
        "\n",
        "                if frame_idx % TEST_ITERS == 0:\n",
        "                    ts = time.time()\n",
        "                    rewards, steps = test_net(act_net, test_env, device = device)\n",
        "                    print('Test done in %.2f sec, reward %.3f, steps %d' % (time.time()-ts, rewards, steps))\n",
        "                    recompensas_ent.append(rewards)\n",
        "                    writer.add_scalar('test_reward', rewards, frame_idx)\n",
        "                    writer.add_scalar('test_steps', steps, frame_idx)\n",
        "                    if best_reward is None or best_reward < rewards:\n",
        "                        if best_reward is not None:\n",
        "                            print('Best reward updated: %.3f -> %.3f' % (best_reward, rewards))\n",
        "                            name = 'best_%+.3f_%d.dat' % (rewards, frame_idx)\n",
        "                            fname = os.path.join(save_path, name)\n",
        "                            torch.save(act_net.state_dict(), fname)\n",
        "                        best_reward = rewards\n",
        "\n",
        "    # se guarda el último estado de la red actor\n",
        "    torch.save(act_net.state_dict(), 'actor_params.pt')\n",
        "    return recompensas_ent\n"
      ],
      "metadata": {
        "id": "GaTAyV5BYj3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta parte:\n",
        "- Se entrena el modelo.\n",
        "- Se obtienen las recompensas respecto a las épocas.\n",
        "- Se grafica la recompensa."
      ],
      "metadata": {
        "id": "q4mrXYRfGZMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recompensas_ent = entrenamiento()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1doDICE0I9H4",
        "outputId": "600e6c3a-cb94-47e9-fb26-206a76b598c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "880: done 79 episodes, mean reward 11.127, speed 879.51 f/s\n",
            "Test done in 0.06 sec, reward 11.500, steps 11\n",
            "1081: done 107 episodes, mean reward 10.030, speed 196.28 f/s\n",
            "1185: done 133 episodes, mean reward 8.350, speed 100.29 f/s\n",
            "1273: done 155 episodes, mean reward 6.800, speed 85.32 f/s\n",
            "1385: done 183 episodes, mean reward 4.710, speed 108.41 f/s\n",
            "1505: done 213 episodes, mean reward 4.000, speed 119.55 f/s\n",
            "1597: done 236 episodes, mean reward 4.000, speed 88.54 f/s\n",
            "1681: done 257 episodes, mean reward 4.000, speed 80.87 f/s\n",
            "1769: done 279 episodes, mean reward 4.000, speed 85.43 f/s\n",
            "1841: done 297 episodes, mean reward 4.000, speed 68.31 f/s\n",
            "1909: done 314 episodes, mean reward 4.000, speed 66.89 f/s\n",
            "1969: done 329 episodes, mean reward 4.000, speed 59.91 f/s\n",
            "Test done in 0.03 sec, reward 3.000, steps 3\n",
            "2041: done 347 episodes, mean reward 4.000, speed 69.09 f/s\n",
            "2129: done 369 episodes, mean reward 4.000, speed 84.62 f/s\n",
            "2213: done 390 episodes, mean reward 4.000, speed 81.28 f/s\n",
            "2265: done 403 episodes, mean reward 4.000, speed 48.18 f/s\n",
            "2305: done 413 episodes, mean reward 4.000, speed 38.75 f/s\n",
            "2345: done 423 episodes, mean reward 4.000, speed 35.41 f/s\n",
            "2389: done 434 episodes, mean reward 4.000, speed 42.97 f/s\n",
            "2433: done 445 episodes, mean reward 4.000, speed 42.01 f/s\n",
            "2485: done 458 episodes, mean reward 4.000, speed 50.49 f/s\n",
            "2561: done 477 episodes, mean reward 4.000, speed 75.84 f/s\n",
            "2625: done 493 episodes, mean reward 4.000, speed 62.32 f/s\n",
            "2753: done 525 episodes, mean reward 4.000, speed 124.44 f/s\n",
            "2889: done 559 episodes, mean reward 4.000, speed 134.11 f/s\n",
            "Test done in 0.02 sec, reward 3.000, steps 3\n",
            "3025: done 593 episodes, mean reward 4.000, speed 134.24 f/s\n",
            "3161: done 627 episodes, mean reward 4.000, speed 133.01 f/s\n",
            "3297: done 661 episodes, mean reward 4.000, speed 133.37 f/s\n",
            "3429: done 694 episodes, mean reward 4.000, speed 130.37 f/s\n",
            "3565: done 724 episodes, mean reward 4.160, speed 135.10 f/s\n",
            "3691: done 742 episodes, mean reward 4.700, speed 119.20 f/s\n",
            "3831: done 749 episodes, mean reward 5.820, speed 109.92 f/s\n",
            "3959: done 753 episodes, mean reward 6.940, speed 109.71 f/s\n",
            "Test done in 0.23 sec, reward 34.100, steps 34\n",
            "Best reward updated: 11.500 -> 34.100\n",
            "4082: done 755 episodes, mean reward 8.090, speed 90.82 f/s\n",
            "4216: done 758 episodes, mean reward 9.310, speed 121.76 f/s\n",
            "4397: done 763 episodes, mean reward 10.920, speed 138.24 f/s\n",
            "4547: done 766 episodes, mean reward 12.300, speed 135.52 f/s\n",
            "4707: done 771 episodes, mean reward 13.700, speed 136.30 f/s\n",
            "4831: done 774 episodes, mean reward 14.820, speed 117.65 f/s\n",
            "4977: done 777 episodes, mean reward 16.160, speed 135.10 f/s\n",
            "Test done in 0.25 sec, reward 47.900, steps 47\n",
            "Best reward updated: 34.100 -> 47.900\n",
            "5138: done 780 episodes, mean reward 17.650, speed 112.56 f/s\n",
            "5344: done 782 episodes, mean reward 19.630, speed 139.69 f/s\n",
            "5500: done 784 episodes, mean reward 21.110, speed 126.59 f/s\n",
            "5634: done 787 episodes, mean reward 22.330, speed 111.35 f/s\n",
            "5777: done 789 episodes, mean reward 23.680, speed 110.48 f/s\n",
            "5939: done 792 episodes, mean reward 25.180, speed 113.43 f/s\n",
            "Test done in 0.03 sec, reward 4.800, steps 4\n",
            "6056: done 794 episodes, mean reward 26.270, speed 116.58 f/s\n",
            "6205: done 796 episodes, mean reward 27.680, speed 138.34 f/s\n",
            "6373: done 799 episodes, mean reward 29.240, speed 134.04 f/s\n",
            "6529: done 803 episodes, mean reward 30.640, speed 134.56 f/s\n",
            "6689: done 807 episodes, mean reward 32.080, speed 137.40 f/s\n",
            "6853: done 811 episodes, mean reward 33.560, speed 140.05 f/s\n",
            "Test done in 0.12 sec, reward 24.000, steps 24\n",
            "7038: done 815 episodes, mean reward 35.250, speed 126.36 f/s\n",
            "7198: done 818 episodes, mean reward 36.630, speed 133.83 f/s\n",
            "7351: done 821 episodes, mean reward 38.010, speed 136.03 f/s\n",
            "7504: done 824 episodes, mean reward 39.390, speed 106.34 f/s\n",
            "7626: done 826 episodes, mean reward 40.500, speed 108.89 f/s\n",
            "7745: done 828 episodes, mean reward 41.590, speed 110.12 f/s\n",
            "7860: done 830 episodes, mean reward 42.620, speed 108.66 f/s\n",
            "Test done in 0.12 sec, reward 22.000, steps 22\n",
            "8029: done 833 episodes, mean reward 44.130, speed 118.56 f/s\n",
            "8225: done 836 episodes, mean reward 45.920, speed 138.28 f/s\n",
            "8416: done 839 episodes, mean reward 47.550, speed 138.50 f/s\n",
            "8612: done 842 episodes, mean reward 49.210, speed 137.76 f/s\n",
            "8805: done 845 episodes, mean reward 50.750, speed 140.32 f/s\n",
            "Test done in 0.17 sec, reward 29.300, steps 29\n",
            "9003: done 848 episodes, mean reward 52.050, speed 125.11 f/s\n",
            "9201: done 851 episodes, mean reward 53.290, speed 137.13 f/s\n",
            "9340: done 853 episodes, mean reward 53.810, speed 114.26 f/s\n",
            "9473: done 855 episodes, mean reward 53.910, speed 108.53 f/s\n",
            "9611: done 857 episodes, mean reward 54.480, speed 109.15 f/s\n",
            "9743: done 859 episodes, mean reward 55.190, speed 108.99 f/s\n",
            "9878: done 861 episodes, mean reward 55.430, speed 130.02 f/s\n",
            "Test done in 0.12 sec, reward 22.400, steps 22\n",
            "10010: done 863 episodes, mean reward 56.130, speed 122.06 f/s\n",
            "10201: done 866 episodes, mean reward 56.540, speed 139.21 f/s\n",
            "10348: done 868 episodes, mean reward 57.270, speed 139.10 f/s\n",
            "10524: done 871 episodes, mean reward 58.170, speed 135.35 f/s\n",
            "10720: done 874 episodes, mean reward 58.890, speed 136.11 f/s\n",
            "10892: done 877 episodes, mean reward 59.150, speed 138.76 f/s\n",
            "Test done in 0.09 sec, reward 16.300, steps 16\n",
            "11055: done 880 episodes, mean reward 59.170, speed 125.52 f/s\n",
            "11240: done 883 episodes, mean reward 58.030, speed 114.40 f/s\n",
            "11404: done 886 episodes, mean reward 58.150, speed 110.85 f/s\n",
            "11551: done 889 episodes, mean reward 57.740, speed 109.80 f/s\n",
            "11674: done 891 episodes, mean reward 57.880, speed 108.98 f/s\n",
            "11795: done 893 episodes, mean reward 57.910, speed 97.01 f/s\n",
            "11917: done 895 episodes, mean reward 57.940, speed 98.90 f/s\n",
            "Test done in 0.15 sec, reward 30.100, steps 30\n",
            "12046: done 897 episodes, mean reward 57.790, speed 91.54 f/s\n",
            "12242: done 900 episodes, mean reward 58.300, speed 137.45 f/s\n",
            "12423: done 903 episodes, mean reward 58.940, speed 141.16 f/s\n",
            "12586: done 906 episodes, mean reward 59.390, speed 137.82 f/s\n",
            "12766: done 909 episodes, mean reward 59.960, speed 137.11 f/s\n",
            "12938: done 912 episodes, mean reward 60.440, speed 125.46 f/s\n",
            "Test done in 0.19 sec, reward 25.200, steps 25\n",
            "13053: done 914 episodes, mean reward 60.670, speed 92.34 f/s\n",
            "13174: done 917 episodes, mean reward 60.330, speed 109.71 f/s\n",
            "13285: done 920 episodes, mean reward 59.880, speed 109.32 f/s\n",
            "13427: done 923 episodes, mean reward 59.790, speed 113.76 f/s\n",
            "13580: done 926 episodes, mean reward 59.540, speed 137.50 f/s\n",
            "13718: done 929 episodes, mean reward 59.190, speed 137.51 f/s\n",
            "13885: done 933 episodes, mean reward 58.560, speed 134.67 f/s\n",
            "Test done in 0.11 sec, reward 19.500, steps 19\n",
            "14017: done 937 episodes, mean reward 57.290, speed 121.18 f/s\n",
            "14196: done 941 episodes, mean reward 56.450, speed 139.33 f/s\n",
            "14346: done 945 episodes, mean reward 55.410, speed 137.25 f/s\n",
            "14522: done 949 episodes, mean reward 54.550, speed 140.01 f/s\n",
            "14676: done 953 episodes, mean reward 53.360, speed 136.67 f/s\n",
            "14812: done 958 episodes, mean reward 51.360, speed 122.88 f/s\n",
            "14950: done 961 episodes, mean reward 50.720, speed 88.36 f/s\n",
            "Test done in 0.17 sec, reward 7.500, steps 7\n",
            "15005: done 963 episodes, mean reward 49.950, speed 47.97 f/s\n",
            "15090: done 965 episodes, mean reward 49.450, speed 52.29 f/s\n",
            "15179: done 967 episodes, mean reward 49.020, speed 64.10 f/s\n",
            "15289: done 971 episodes, mean reward 47.650, speed 77.66 f/s\n",
            "15390: done 974 episodes, mean reward 46.700, speed 69.58 f/s\n",
            "15491: done 977 episodes, mean reward 45.990, speed 74.45 f/s\n",
            "15585: done 980 episodes, mean reward 45.300, speed 63.08 f/s\n",
            "15668: done 982 episodes, mean reward 44.960, speed 77.49 f/s\n",
            "15759: done 984 episodes, mean reward 44.530, speed 62.13 f/s\n",
            "15911: done 987 episodes, mean reward 44.610, speed 127.60 f/s\n",
            "Test done in 0.09 sec, reward 13.400, steps 13\n",
            "16024: done 990 episodes, mean reward 44.170, speed 99.62 f/s\n",
            "16138: done 994 episodes, mean reward 42.960, speed 107.80 f/s\n",
            "16282: done 997 episodes, mean reward 42.360, speed 110.96 f/s\n",
            "16403: done 1001 episodes, mean reward 40.970, speed 110.15 f/s\n",
            "16543: done 1005 episodes, mean reward 40.130, speed 133.06 f/s\n",
            "16698: done 1010 episodes, mean reward 38.900, speed 139.65 f/s\n",
            "16868: done 1015 episodes, mean reward 37.740, speed 141.42 f/s\n",
            "Test done in 0.04 sec, reward 6.500, steps 6\n",
            "17007: done 1019 episodes, mean reward 37.710, speed 135.13 f/s\n",
            "17193: done 1023 episodes, mean reward 37.660, speed 137.31 f/s\n",
            "17339: done 1026 episodes, mean reward 37.590, speed 140.06 f/s\n",
            "17513: done 1030 episodes, mean reward 37.520, speed 136.95 f/s\n",
            "17698: done 1034 episodes, mean reward 37.750, speed 138.46 f/s\n",
            "17835: done 1038 episodes, mean reward 37.780, speed 127.93 f/s\n",
            "17965: done 1041 episodes, mean reward 37.690, speed 109.56 f/s\n",
            "Test done in 0.13 sec, reward 19.400, steps 19\n",
            "18091: done 1047 episodes, mean reward 36.580, speed 98.61 f/s\n",
            "18221: done 1051 episodes, mean reward 36.310, speed 109.54 f/s\n",
            "18334: done 1056 episodes, mean reward 35.830, speed 112.35 f/s\n",
            "18495: done 1062 episodes, mean reward 35.010, speed 136.22 f/s\n",
            "18636: done 1067 episodes, mean reward 34.570, speed 138.40 f/s\n",
            "18780: done 1074 episodes, mean reward 33.900, speed 136.15 f/s\n",
            "18934: done 1078 episodes, mean reward 34.020, speed 139.77 f/s\n",
            "Test done in 0.09 sec, reward 15.300, steps 15\n",
            "19065: done 1082 episodes, mean reward 33.970, speed 124.87 f/s\n",
            "19219: done 1086 episodes, mean reward 33.420, speed 135.39 f/s\n",
            "19359: done 1091 episodes, mean reward 32.960, speed 138.92 f/s\n",
            "19504: done 1098 episodes, mean reward 32.080, speed 139.59 f/s\n",
            "19646: done 1103 episodes, mean reward 31.800, speed 137.88 f/s\n",
            "19784: done 1110 episodes, mean reward 30.860, speed 114.65 f/s\n",
            "19903: done 1115 episodes, mean reward 30.350, speed 112.89 f/s\n",
            "Test done in 0.11 sec, reward 16.800, steps 16\n",
            "20023: done 1118 episodes, mean reward 30.600, speed 99.82 f/s\n",
            "20163: done 1123 episodes, mean reward 29.700, speed 107.25 f/s\n",
            "20289: done 1127 episodes, mean reward 29.100, speed 124.67 f/s\n",
            "20430: done 1134 episodes, mean reward 27.320, speed 139.01 f/s\n",
            "20569: done 1141 episodes, mean reward 26.040, speed 138.37 f/s\n",
            "20729: done 1148 episodes, mean reward 26.250, speed 139.74 f/s\n",
            "20889: done 1152 episodes, mean reward 26.540, speed 140.27 f/s\n",
            "Test done in 0.12 sec, reward 23.700, steps 23\n",
            "21014: done 1155 episodes, mean reward 27.180, speed 123.37 f/s\n",
            "21183: done 1159 episodes, mean reward 27.790, speed 137.64 f/s\n",
            "21358: done 1164 episodes, mean reward 28.110, speed 140.27 f/s\n",
            "21520: done 1169 episodes, mean reward 28.290, speed 135.37 f/s\n",
            "21670: done 1174 episodes, mean reward 28.900, speed 117.27 f/s\n",
            "21786: done 1177 episodes, mean reward 28.910, speed 114.27 f/s\n",
            "21908: done 1180 episodes, mean reward 29.230, speed 112.65 f/s\n",
            "Test done in 0.13 sec, reward 19.600, steps 19\n",
            "22034: done 1184 episodes, mean reward 28.910, speed 98.78 f/s\n",
            "22155: done 1187 episodes, mean reward 29.220, speed 115.58 f/s\n",
            "22323: done 1191 episodes, mean reward 29.640, speed 138.99 f/s\n",
            "22483: done 1195 episodes, mean reward 30.460, speed 138.65 f/s\n",
            "22651: done 1199 episodes, mean reward 31.110, speed 138.44 f/s\n",
            "22832: done 1203 episodes, mean reward 31.860, speed 138.97 f/s\n",
            "22995: done 1207 episodes, mean reward 32.730, speed 137.61 f/s\n",
            "Test done in 0.14 sec, reward 25.200, steps 25\n",
            "23114: done 1210 episodes, mean reward 33.300, speed 118.77 f/s\n",
            "23271: done 1214 episodes, mean reward 33.820, speed 140.22 f/s\n",
            "23448: done 1220 episodes, mean reward 33.760, speed 139.59 f/s\n",
            "23577: done 1224 episodes, mean reward 34.030, speed 115.15 f/s\n",
            "23696: done 1227 episodes, mean reward 34.070, speed 112.18 f/s\n",
            "23813: done 1230 episodes, mean reward 34.580, speed 113.45 f/s\n",
            "23962: done 1234 episodes, mean reward 35.320, speed 110.59 f/s\n",
            "Test done in 0.17 sec, reward 22.000, steps 22\n",
            "24093: done 1238 episodes, mean reward 35.870, speed 107.09 f/s\n",
            "24263: done 1243 episodes, mean reward 36.690, speed 135.82 f/s\n",
            "24437: done 1248 episodes, mean reward 37.080, speed 138.56 f/s\n",
            "24600: done 1252 episodes, mean reward 37.110, speed 138.45 f/s\n",
            "24765: done 1256 episodes, mean reward 37.050, speed 138.22 f/s\n",
            "24929: done 1260 episodes, mean reward 37.350, speed 139.98 f/s\n",
            "Test done in 0.16 sec, reward 31.200, steps 31\n",
            "25050: done 1263 episodes, mean reward 37.300, speed 114.41 f/s\n",
            "25207: done 1267 episodes, mean reward 37.370, speed 139.68 f/s\n",
            "25376: done 1272 episodes, mean reward 37.600, speed 132.45 f/s\n",
            "25493: done 1275 episodes, mean reward 37.860, speed 106.59 f/s\n",
            "25609: done 1278 episodes, mean reward 37.820, speed 109.45 f/s\n",
            "25725: done 1281 episodes, mean reward 37.800, speed 110.93 f/s\n",
            "25842: done 1284 episodes, mean reward 38.080, speed 111.49 f/s\n",
            "25994: done 1288 episodes, mean reward 37.990, speed 107.92 f/s\n",
            "Test done in 0.19 sec, reward 28.800, steps 28\n",
            "26072: done 1290 episodes, mean reward 37.890, speed 66.41 f/s\n",
            "26187: done 1293 episodes, mean reward 37.860, speed 102.70 f/s\n",
            "26346: done 1297 episodes, mean reward 37.730, speed 140.13 f/s\n",
            "26496: done 1301 episodes, mean reward 37.540, speed 139.18 f/s\n",
            "26650: done 1305 episodes, mean reward 37.390, speed 133.14 f/s\n",
            "26798: done 1309 episodes, mean reward 37.270, speed 139.10 f/s\n",
            "26959: done 1313 episodes, mean reward 37.300, speed 138.81 f/s\n",
            "Test done in 0.14 sec, reward 27.500, steps 27\n",
            "27115: done 1317 episodes, mean reward 37.530, speed 123.82 f/s\n",
            "27232: done 1320 episodes, mean reward 37.840, speed 110.44 f/s\n",
            "27350: done 1323 episodes, mean reward 38.100, speed 109.26 f/s\n",
            "27463: done 1326 episodes, mean reward 38.060, speed 108.52 f/s\n",
            "27582: done 1329 episodes, mean reward 38.100, speed 110.70 f/s\n",
            "27702: done 1332 episodes, mean reward 38.150, speed 116.34 f/s\n",
            "27866: done 1336 episodes, mean reward 38.490, speed 140.89 f/s\n",
            "Test done in 0.14 sec, reward 28.000, steps 28\n",
            "28033: done 1340 episodes, mean reward 38.870, speed 123.36 f/s\n",
            "28190: done 1344 episodes, mean reward 38.880, speed 140.01 f/s\n",
            "28350: done 1348 episodes, mean reward 39.130, speed 137.84 f/s\n",
            "28512: done 1352 episodes, mean reward 39.120, speed 140.66 f/s\n",
            "28676: done 1356 episodes, mean reward 39.110, speed 140.19 f/s\n",
            "28838: done 1360 episodes, mean reward 39.090, speed 138.30 f/s\n",
            "Test done in 0.17 sec, reward 34.000, steps 34\n",
            "29010: done 1364 episodes, mean reward 39.210, speed 118.59 f/s\n",
            "29132: done 1367 episodes, mean reward 39.250, speed 105.19 f/s\n",
            "29252: done 1370 episodes, mean reward 39.510, speed 107.42 f/s\n",
            "29371: done 1373 episodes, mean reward 39.560, speed 112.79 f/s\n",
            "29493: done 1376 episodes, mean reward 39.630, speed 110.83 f/s\n",
            "29614: done 1379 episodes, mean reward 39.680, speed 118.27 f/s\n",
            "29772: done 1383 episodes, mean reward 39.700, speed 135.63 f/s\n",
            "29926: done 1387 episodes, mean reward 39.710, speed 141.19 f/s\n",
            "Test done in 0.14 sec, reward 26.400, steps 26\n",
            "30051: done 1390 episodes, mean reward 39.790, speed 120.00 f/s\n",
            "30206: done 1394 episodes, mean reward 39.800, speed 140.26 f/s\n",
            "30360: done 1398 episodes, mean reward 39.760, speed 139.84 f/s\n",
            "30529: done 1402 episodes, mean reward 39.970, speed 137.92 f/s\n",
            "30693: done 1406 episodes, mean reward 40.080, speed 136.19 f/s\n",
            "30858: done 1410 episodes, mean reward 40.230, speed 137.28 f/s\n",
            "30979: done 1413 episodes, mean reward 40.200, speed 118.78 f/s\n",
            "Test done in 0.21 sec, reward 29.700, steps 29\n",
            "31100: done 1416 episodes, mean reward 40.220, speed 92.68 f/s\n",
            "31216: done 1419 episodes, mean reward 40.250, speed 110.55 f/s\n",
            "31335: done 1422 episodes, mean reward 40.240, speed 112.19 f/s\n",
            "31451: done 1425 episodes, mean reward 40.260, speed 112.90 f/s\n",
            "31615: done 1429 episodes, mean reward 40.330, speed 139.46 f/s\n",
            "31770: done 1433 episodes, mean reward 40.280, speed 137.84 f/s\n",
            "31928: done 1437 episodes, mean reward 40.200, speed 137.51 f/s\n",
            "Test done in 0.18 sec, reward 34.600, steps 34\n",
            "32054: done 1440 episodes, mean reward 40.210, speed 114.33 f/s\n",
            "32221: done 1444 episodes, mean reward 40.310, speed 137.04 f/s\n",
            "32386: done 1448 episodes, mean reward 40.360, speed 136.75 f/s\n",
            "32548: done 1452 episodes, mean reward 40.360, speed 138.41 f/s\n",
            "32711: done 1456 episodes, mean reward 40.350, speed 138.02 f/s\n",
            "32871: done 1460 episodes, mean reward 40.330, speed 119.73 f/s\n",
            "32997: done 1463 episodes, mean reward 40.320, speed 109.91 f/s\n",
            "Test done in 0.29 sec, reward 43.700, steps 43\n",
            "33081: done 1465 episodes, mean reward 40.300, speed 79.08 f/s\n",
            "33214: done 1468 episodes, mean reward 40.390, speed 109.36 f/s\n",
            "33341: done 1471 episodes, mean reward 40.480, speed 120.88 f/s\n",
            "33501: done 1475 episodes, mean reward 40.510, speed 140.20 f/s\n",
            "33667: done 1479 episodes, mean reward 40.530, speed 139.29 f/s\n",
            "33823: done 1483 episodes, mean reward 40.510, speed 139.01 f/s\n",
            "33984: done 1487 episodes, mean reward 40.580, speed 136.26 f/s\n",
            "Test done in 0.13 sec, reward 22.800, steps 22\n",
            "34144: done 1491 episodes, mean reward 40.520, speed 123.31 f/s\n",
            "34309: done 1495 episodes, mean reward 40.640, speed 135.63 f/s\n",
            "34467: done 1499 episodes, mean reward 40.680, speed 137.16 f/s\n",
            "34624: done 1503 episodes, mean reward 40.540, speed 134.31 f/s\n",
            "34739: done 1506 episodes, mean reward 40.460, speed 102.18 f/s\n",
            "34856: done 1509 episodes, mean reward 40.410, speed 112.17 f/s\n",
            "34976: done 1512 episodes, mean reward 40.370, speed 109.38 f/s\n",
            "Test done in 0.19 sec, reward 25.900, steps 25\n",
            "35100: done 1515 episodes, mean reward 40.400, speed 93.09 f/s\n",
            "35250: done 1519 episodes, mean reward 40.340, speed 123.26 f/s\n",
            "35408: done 1523 episodes, mean reward 40.360, speed 141.21 f/s\n",
            "35566: done 1527 episodes, mean reward 40.310, speed 137.86 f/s\n",
            "35724: done 1531 episodes, mean reward 40.300, speed 139.12 f/s\n",
            "35886: done 1535 episodes, mean reward 40.350, speed 137.08 f/s\n",
            "Test done in 0.18 sec, reward 32.800, steps 32\n",
            "36006: done 1538 episodes, mean reward 40.360, speed 113.51 f/s\n",
            "36173: done 1542 episodes, mean reward 40.350, speed 139.76 f/s\n",
            "36341: done 1546 episodes, mean reward 40.390, speed 139.94 f/s\n",
            "36494: done 1550 episodes, mean reward 40.260, speed 138.52 f/s\n",
            "36615: done 1553 episodes, mean reward 40.270, speed 115.31 f/s\n",
            "36738: done 1556 episodes, mean reward 40.270, speed 108.35 f/s\n",
            "36887: done 1560 episodes, mean reward 40.160, speed 110.45 f/s\n",
            "Test done in 0.21 sec, reward 29.300, steps 29\n",
            "37005: done 1563 episodes, mean reward 40.080, speed 90.38 f/s\n",
            "37161: done 1567 episodes, mean reward 39.910, speed 130.34 f/s\n",
            "37319: done 1571 episodes, mean reward 39.780, speed 138.95 f/s\n",
            "37469: done 1575 episodes, mean reward 39.680, speed 137.73 f/s\n",
            "37622: done 1579 episodes, mean reward 39.550, speed 138.99 f/s\n",
            "37772: done 1583 episodes, mean reward 39.490, speed 138.35 f/s\n",
            "37932: done 1587 episodes, mean reward 39.480, speed 138.99 f/s\n",
            "Test done in 0.15 sec, reward 27.000, steps 27\n",
            "38058: done 1590 episodes, mean reward 39.550, speed 116.65 f/s\n",
            "38216: done 1594 episodes, mean reward 39.460, speed 139.36 f/s\n",
            "38383: done 1599 episodes, mean reward 39.160, speed 141.43 f/s\n",
            "38532: done 1603 episodes, mean reward 39.080, speed 111.71 f/s\n",
            "38669: done 1607 episodes, mean reward 38.910, speed 109.93 f/s\n",
            "38801: done 1611 episodes, mean reward 38.670, speed 110.22 f/s\n",
            "38942: done 1615 episodes, mean reward 38.420, speed 110.72 f/s\n",
            "Test done in 0.12 sec, reward 23.500, steps 23\n",
            "39089: done 1619 episodes, mean reward 38.390, speed 124.83 f/s\n",
            "39253: done 1624 episodes, mean reward 38.060, speed 139.10 f/s\n",
            "39424: done 1629 episodes, mean reward 37.770, speed 138.42 f/s\n",
            "39565: done 1633 episodes, mean reward 37.620, speed 138.06 f/s\n",
            "39727: done 1637 episodes, mean reward 37.610, speed 138.11 f/s\n",
            "39872: done 1641 episodes, mean reward 37.420, speed 135.35 f/s\n",
            "Test done in 0.13 sec, reward 24.800, steps 24\n",
            "40021: done 1645 episodes, mean reward 37.220, speed 124.06 f/s\n",
            "40181: done 1649 episodes, mean reward 37.280, speed 139.81 f/s\n",
            "40348: done 1653 episodes, mean reward 37.330, speed 128.77 f/s\n",
            "40499: done 1657 episodes, mean reward 37.210, speed 109.89 f/s\n",
            "40610: done 1660 episodes, mean reward 37.230, speed 109.68 f/s\n",
            "40721: done 1663 episodes, mean reward 37.160, speed 107.59 f/s\n",
            "40840: done 1666 episodes, mean reward 37.170, speed 108.95 f/s\n",
            "40979: done 1670 episodes, mean reward 36.990, speed 136.70 f/s\n",
            "Test done in 0.14 sec, reward 26.000, steps 26\n",
            "41127: done 1674 episodes, mean reward 36.960, speed 118.78 f/s\n",
            "41284: done 1678 episodes, mean reward 37.030, speed 138.88 f/s\n",
            "41446: done 1682 episodes, mean reward 37.140, speed 138.54 f/s\n",
            "41591: done 1686 episodes, mean reward 37.000, speed 137.51 f/s\n",
            "41732: done 1690 episodes, mean reward 36.740, speed 133.26 f/s\n",
            "41884: done 1694 episodes, mean reward 36.680, speed 141.04 f/s\n",
            "Test done in 0.15 sec, reward 29.200, steps 29\n",
            "42037: done 1698 episodes, mean reward 36.850, speed 118.17 f/s\n",
            "42193: done 1702 episodes, mean reward 36.990, speed 129.17 f/s\n",
            "42315: done 1705 episodes, mean reward 37.150, speed 111.14 f/s\n",
            "42435: done 1708 episodes, mean reward 37.370, speed 106.86 f/s\n",
            "42563: done 1711 episodes, mean reward 37.620, speed 110.06 f/s\n",
            "42681: done 1714 episodes, mean reward 37.750, speed 110.74 f/s\n",
            "42842: done 1718 episodes, mean reward 37.880, speed 134.50 f/s\n",
            "Test done in 0.15 sec, reward 29.800, steps 29\n",
            "43002: done 1722 episodes, mean reward 38.150, speed 121.42 f/s\n",
            "43165: done 1726 episodes, mean reward 38.400, speed 137.22 f/s\n",
            "43317: done 1730 episodes, mean reward 38.640, speed 136.79 f/s\n",
            "43472: done 1734 episodes, mean reward 38.670, speed 137.40 f/s\n",
            "43632: done 1738 episodes, mean reward 38.660, speed 136.47 f/s\n",
            "43804: done 1742 episodes, mean reward 38.930, speed 137.67 f/s\n",
            "43965: done 1746 episodes, mean reward 39.060, speed 136.58 f/s\n",
            "Test done in 0.15 sec, reward 25.700, steps 25\n",
            "44082: done 1749 episodes, mean reward 39.010, speed 104.36 f/s\n",
            "44200: done 1752 episodes, mean reward 38.930, speed 107.35 f/s\n",
            "44317: done 1755 episodes, mean reward 38.920, speed 106.95 f/s\n",
            "44435: done 1758 episodes, mean reward 38.990, speed 111.83 f/s\n",
            "44555: done 1761 episodes, mean reward 39.090, speed 111.80 f/s\n",
            "44710: done 1765 episodes, mean reward 39.120, speed 135.13 f/s\n",
            "44869: done 1769 episodes, mean reward 39.270, speed 137.70 f/s\n",
            "Test done in 0.16 sec, reward 28.700, steps 28\n",
            "45022: done 1773 episodes, mean reward 39.340, speed 121.68 f/s\n",
            "45178: done 1777 episodes, mean reward 39.350, speed 137.50 f/s\n",
            "45333: done 1781 episodes, mean reward 39.270, speed 139.18 f/s\n",
            "45497: done 1785 episodes, mean reward 39.370, speed 138.82 f/s\n",
            "45666: done 1789 episodes, mean reward 39.660, speed 139.48 f/s\n",
            "45829: done 1793 episodes, mean reward 39.810, speed 135.47 f/s\n",
            "45988: done 1797 episodes, mean reward 39.900, speed 125.31 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "46108: done 1800 episodes, mean reward 39.920, speed 104.97 f/s\n",
            "46230: done 1803 episodes, mean reward 39.960, speed 110.44 f/s\n",
            "46345: done 1806 episodes, mean reward 39.900, speed 110.68 f/s\n",
            "46463: done 1809 episodes, mean reward 39.870, speed 112.97 f/s\n",
            "46616: done 1813 episodes, mean reward 39.740, speed 138.60 f/s\n",
            "46771: done 1817 episodes, mean reward 39.710, speed 139.76 f/s\n",
            "46923: done 1821 episodes, mean reward 39.620, speed 136.97 f/s\n",
            "Test done in 0.16 sec, reward 31.100, steps 31\n",
            "47040: done 1824 episodes, mean reward 39.570, speed 115.21 f/s\n",
            "47190: done 1828 episodes, mean reward 39.500, speed 136.99 f/s\n",
            "47343: done 1832 episodes, mean reward 39.500, speed 136.80 f/s\n",
            "47493: done 1836 episodes, mean reward 39.410, speed 138.47 f/s\n",
            "47647: done 1840 episodes, mean reward 39.290, speed 138.64 f/s\n",
            "47807: done 1844 episodes, mean reward 39.230, speed 137.11 f/s\n",
            "47926: done 1847 episodes, mean reward 39.210, speed 111.37 f/s\n",
            "Test done in 0.28 sec, reward 40.700, steps 40\n",
            "48040: done 1850 episodes, mean reward 39.170, speed 86.39 f/s\n",
            "48153: done 1853 episodes, mean reward 39.140, speed 112.15 f/s\n",
            "48269: done 1856 episodes, mean reward 39.130, speed 110.22 f/s\n",
            "48423: done 1860 episodes, mean reward 39.070, speed 123.91 f/s\n",
            "48577: done 1864 episodes, mean reward 39.060, speed 134.31 f/s\n",
            "48728: done 1868 episodes, mean reward 38.970, speed 137.97 f/s\n",
            "48882: done 1872 episodes, mean reward 38.980, speed 136.53 f/s\n",
            "Test done in 0.12 sec, reward 21.700, steps 21\n",
            "49029: done 1876 episodes, mean reward 38.880, speed 123.29 f/s\n",
            "49175: done 1880 episodes, mean reward 38.800, speed 134.89 f/s\n",
            "49324: done 1884 episodes, mean reward 38.690, speed 137.67 f/s\n",
            "49474: done 1888 episodes, mean reward 38.500, speed 137.25 f/s\n",
            "49627: done 1892 episodes, mean reward 38.400, speed 135.33 f/s\n",
            "49781: done 1896 episodes, mean reward 38.320, speed 112.32 f/s\n",
            "49898: done 1899 episodes, mean reward 38.300, speed 111.68 f/s\n",
            "Test done in 0.24 sec, reward 35.200, steps 35\n",
            "50013: done 1902 episodes, mean reward 38.250, speed 87.38 f/s\n",
            "50125: done 1905 episodes, mean reward 38.170, speed 111.31 f/s\n",
            "50271: done 1909 episodes, mean reward 38.080, speed 124.24 f/s\n",
            "50426: done 1913 episodes, mean reward 38.100, speed 134.45 f/s\n",
            "50584: done 1917 episodes, mean reward 38.130, speed 134.53 f/s\n",
            "50745: done 1921 episodes, mean reward 38.220, speed 138.01 f/s\n",
            "50895: done 1925 episodes, mean reward 38.190, speed 136.33 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "51045: done 1929 episodes, mean reward 38.160, speed 130.75 f/s\n",
            "51206: done 1933 episodes, mean reward 38.260, speed 133.73 f/s\n",
            "51362: done 1937 episodes, mean reward 38.320, speed 134.74 f/s\n",
            "51519: done 1941 episodes, mean reward 38.320, speed 138.82 f/s\n",
            "51636: done 1944 episodes, mean reward 38.290, speed 107.43 f/s\n",
            "51748: done 1947 episodes, mean reward 38.220, speed 106.41 f/s\n",
            "51865: done 1950 episodes, mean reward 38.250, speed 109.52 f/s\n",
            "51978: done 1953 episodes, mean reward 38.250, speed 110.35 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "52088: done 1956 episodes, mean reward 38.190, speed 107.92 f/s\n",
            "52239: done 1960 episodes, mean reward 38.160, speed 138.77 f/s\n",
            "52392: done 1964 episodes, mean reward 38.150, speed 138.40 f/s\n",
            "52542: done 1968 episodes, mean reward 38.140, speed 139.71 f/s\n",
            "52694: done 1972 episodes, mean reward 38.120, speed 139.08 f/s\n",
            "52846: done 1976 episodes, mean reward 38.170, speed 138.36 f/s\n",
            "52999: done 1980 episodes, mean reward 38.240, speed 137.71 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "53151: done 1984 episodes, mean reward 38.270, speed 131.32 f/s\n",
            "53302: done 1988 episodes, mean reward 38.280, speed 136.67 f/s\n",
            "53453: done 1992 episodes, mean reward 38.260, speed 129.99 f/s\n",
            "53563: done 1995 episodes, mean reward 38.210, speed 108.03 f/s\n",
            "53711: done 1999 episodes, mean reward 38.130, speed 111.78 f/s\n",
            "53857: done 2003 episodes, mean reward 38.070, speed 112.65 f/s\n",
            "53972: done 2006 episodes, mean reward 38.110, speed 110.58 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "54121: done 2010 episodes, mean reward 38.110, speed 130.40 f/s\n",
            "54266: done 2014 episodes, mean reward 38.010, speed 137.27 f/s\n",
            "54413: done 2018 episodes, mean reward 37.870, speed 135.96 f/s\n",
            "54561: done 2022 episodes, mean reward 37.790, speed 136.75 f/s\n",
            "54709: done 2026 episodes, mean reward 37.760, speed 140.61 f/s\n",
            "54859: done 2030 episodes, mean reward 37.750, speed 138.88 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "55007: done 2034 episodes, mean reward 37.610, speed 134.27 f/s\n",
            "55158: done 2038 episodes, mean reward 37.580, speed 136.63 f/s\n",
            "55307: done 2042 episodes, mean reward 37.480, speed 140.13 f/s\n",
            "55422: done 2045 episodes, mean reward 37.510, speed 111.37 f/s\n",
            "55535: done 2048 episodes, mean reward 37.490, speed 111.52 f/s\n",
            "55649: done 2051 episodes, mean reward 37.460, speed 111.80 f/s\n",
            "55762: done 2054 episodes, mean reward 37.490, speed 107.93 f/s\n",
            "55884: done 2057 episodes, mean reward 37.590, speed 113.32 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "56038: done 2061 episodes, mean reward 37.610, speed 129.87 f/s\n",
            "56192: done 2065 episodes, mean reward 37.610, speed 135.25 f/s\n",
            "56346: done 2069 episodes, mean reward 37.670, speed 135.88 f/s\n",
            "56496: done 2073 episodes, mean reward 37.650, speed 138.23 f/s\n",
            "56650: done 2077 episodes, mean reward 37.640, speed 135.79 f/s\n",
            "56800: done 2081 episodes, mean reward 37.640, speed 137.85 f/s\n",
            "56952: done 2085 episodes, mean reward 37.640, speed 135.51 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "57102: done 2089 episodes, mean reward 37.630, speed 129.47 f/s\n",
            "57251: done 2093 episodes, mean reward 37.630, speed 125.65 f/s\n",
            "57361: done 2096 episodes, mean reward 37.610, speed 109.60 f/s\n",
            "57473: done 2099 episodes, mean reward 37.620, speed 110.42 f/s\n",
            "57584: done 2102 episodes, mean reward 37.640, speed 109.78 f/s\n",
            "57700: done 2105 episodes, mean reward 37.660, speed 109.22 f/s\n",
            "57849: done 2109 episodes, mean reward 37.650, speed 121.91 f/s\n",
            "57998: done 2113 episodes, mean reward 37.700, speed 138.45 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "58148: done 2117 episodes, mean reward 37.720, speed 130.34 f/s\n",
            "58293: done 2121 episodes, mean reward 37.690, speed 139.23 f/s\n",
            "58431: done 2125 episodes, mean reward 37.600, speed 137.75 f/s\n",
            "58579: done 2129 episodes, mean reward 37.590, speed 139.70 f/s\n",
            "58727: done 2133 episodes, mean reward 37.560, speed 138.43 f/s\n",
            "58878: done 2137 episodes, mean reward 37.570, speed 137.62 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "59027: done 2141 episodes, mean reward 37.570, speed 132.65 f/s\n",
            "59181: done 2145 episodes, mean reward 37.590, speed 122.70 f/s\n",
            "59296: done 2148 episodes, mean reward 37.610, speed 110.06 f/s\n",
            "59410: done 2151 episodes, mean reward 37.610, speed 106.17 f/s\n",
            "59557: done 2155 episodes, mean reward 37.550, speed 110.45 f/s\n",
            "59666: done 2158 episodes, mean reward 37.420, speed 106.99 f/s\n",
            "59817: done 2162 episodes, mean reward 37.400, speed 137.80 f/s\n",
            "59961: done 2166 episodes, mean reward 37.320, speed 137.49 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "60110: done 2170 episodes, mean reward 37.270, speed 131.33 f/s\n",
            "60263: done 2174 episodes, mean reward 37.290, speed 139.54 f/s\n",
            "60414: done 2178 episodes, mean reward 37.270, speed 138.15 f/s\n",
            "60554: done 2182 episodes, mean reward 37.170, speed 138.25 f/s\n",
            "60703: done 2186 episodes, mean reward 37.140, speed 138.97 f/s\n",
            "60850: done 2190 episodes, mean reward 37.100, speed 138.06 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "61026: done 2195 episodes, mean reward 37.010, speed 132.44 f/s\n",
            "61139: done 2198 episodes, mean reward 37.020, speed 102.85 f/s\n",
            "61280: done 2202 episodes, mean reward 36.960, speed 109.10 f/s\n",
            "61391: done 2205 episodes, mean reward 36.910, speed 108.32 f/s\n",
            "61502: done 2208 episodes, mean reward 36.900, speed 110.79 f/s\n",
            "61651: done 2212 episodes, mean reward 36.920, speed 122.84 f/s\n",
            "61801: done 2216 episodes, mean reward 36.900, speed 138.68 f/s\n",
            "61944: done 2220 episodes, mean reward 36.860, speed 139.29 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "62098: done 2224 episodes, mean reward 37.030, speed 131.93 f/s\n",
            "62250: done 2228 episodes, mean reward 37.080, speed 135.91 f/s\n",
            "62398: done 2232 episodes, mean reward 37.100, speed 136.96 f/s\n",
            "62545: done 2236 episodes, mean reward 37.050, speed 134.87 f/s\n",
            "62692: done 2240 episodes, mean reward 37.020, speed 136.70 f/s\n",
            "62841: done 2244 episodes, mean reward 36.990, speed 133.44 f/s\n",
            "62992: done 2248 episodes, mean reward 36.960, speed 120.56 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "63102: done 2251 episodes, mean reward 36.920, speed 102.85 f/s\n",
            "63215: done 2254 episodes, mean reward 36.950, speed 111.24 f/s\n",
            "63361: done 2258 episodes, mean reward 36.950, speed 112.84 f/s\n",
            "63509: done 2262 episodes, mean reward 36.920, speed 119.68 f/s\n",
            "63664: done 2266 episodes, mean reward 37.030, speed 136.79 f/s\n",
            "63818: done 2270 episodes, mean reward 37.080, speed 134.07 f/s\n",
            "63972: done 2274 episodes, mean reward 37.090, speed 138.47 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "64117: done 2278 episodes, mean reward 37.030, speed 127.18 f/s\n",
            "64269: done 2282 episodes, mean reward 37.150, speed 134.30 f/s\n",
            "64417: done 2286 episodes, mean reward 37.140, speed 136.90 f/s\n",
            "64561: done 2290 episodes, mean reward 37.110, speed 133.57 f/s\n",
            "64708: done 2294 episodes, mean reward 37.200, speed 134.57 f/s\n",
            "64858: done 2298 episodes, mean reward 37.190, speed 123.16 f/s\n",
            "64971: done 2301 episodes, mean reward 37.280, speed 109.64 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "65085: done 2304 episodes, mean reward 37.310, speed 101.79 f/s\n",
            "65199: done 2307 episodes, mean reward 37.340, speed 107.16 f/s\n",
            "65310: done 2310 episodes, mean reward 37.320, speed 101.77 f/s\n",
            "65460: done 2314 episodes, mean reward 37.340, speed 125.13 f/s\n",
            "65609: done 2318 episodes, mean reward 37.390, speed 137.68 f/s\n",
            "65759: done 2322 episodes, mean reward 37.370, speed 138.08 f/s\n",
            "65910: done 2326 episodes, mean reward 37.370, speed 137.93 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "66061: done 2330 episodes, mean reward 37.390, speed 129.45 f/s\n",
            "66211: done 2334 episodes, mean reward 37.380, speed 136.63 f/s\n",
            "66359: done 2338 episodes, mean reward 37.390, speed 137.64 f/s\n",
            "66510: done 2342 episodes, mean reward 37.440, speed 136.82 f/s\n",
            "66655: done 2346 episodes, mean reward 37.380, speed 137.87 f/s\n",
            "66805: done 2350 episodes, mean reward 37.400, speed 117.75 f/s\n",
            "66917: done 2353 episodes, mean reward 37.400, speed 111.97 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "67027: done 2356 episodes, mean reward 37.390, speed 103.43 f/s\n",
            "67174: done 2360 episodes, mean reward 37.400, speed 111.10 f/s\n",
            "67323: done 2364 episodes, mean reward 37.370, speed 118.19 f/s\n",
            "67470: done 2368 episodes, mean reward 37.280, speed 134.83 f/s\n",
            "67619: done 2372 episodes, mean reward 37.220, speed 132.74 f/s\n",
            "67769: done 2376 episodes, mean reward 37.240, speed 137.62 f/s\n",
            "67921: done 2380 episodes, mean reward 37.270, speed 135.83 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "68066: done 2384 episodes, mean reward 37.240, speed 132.50 f/s\n",
            "68211: done 2388 episodes, mean reward 37.220, speed 135.44 f/s\n",
            "68358: done 2392 episodes, mean reward 37.240, speed 138.08 f/s\n",
            "68505: done 2396 episodes, mean reward 37.230, speed 138.19 f/s\n",
            "68657: done 2400 episodes, mean reward 37.240, speed 127.75 f/s\n",
            "68769: done 2403 episodes, mean reward 37.210, speed 107.85 f/s\n",
            "68881: done 2406 episodes, mean reward 37.210, speed 110.15 f/s\n",
            "68993: done 2409 episodes, mean reward 37.200, speed 109.66 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "69105: done 2412 episodes, mean reward 37.210, speed 103.92 f/s\n",
            "69253: done 2416 episodes, mean reward 37.200, speed 131.79 f/s\n",
            "69402: done 2420 episodes, mean reward 37.180, speed 139.07 f/s\n",
            "69548: done 2424 episodes, mean reward 37.150, speed 137.31 f/s\n",
            "69701: done 2428 episodes, mean reward 37.160, speed 137.14 f/s\n",
            "69850: done 2432 episodes, mean reward 37.140, speed 137.40 f/s\n",
            "70000: done 2436 episodes, mean reward 37.170, speed 136.40 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "70146: done 2440 episodes, mean reward 37.110, speed 132.39 f/s\n",
            "70298: done 2444 episodes, mean reward 37.160, speed 137.01 f/s\n",
            "70448: done 2448 episodes, mean reward 37.160, speed 137.95 f/s\n",
            "70598: done 2452 episodes, mean reward 37.180, speed 117.74 f/s\n",
            "70747: done 2456 episodes, mean reward 37.200, speed 112.62 f/s\n",
            "70897: done 2460 episodes, mean reward 37.230, speed 110.11 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "71009: done 2463 episodes, mean reward 37.240, speed 105.39 f/s\n",
            "71160: done 2467 episodes, mean reward 37.260, speed 132.28 f/s\n",
            "71311: done 2471 episodes, mean reward 37.290, speed 139.70 f/s\n",
            "71460: done 2475 episodes, mean reward 37.280, speed 137.16 f/s\n",
            "71611: done 2479 episodes, mean reward 37.280, speed 133.51 f/s\n",
            "71759: done 2483 episodes, mean reward 37.290, speed 138.67 f/s\n",
            "71904: done 2487 episodes, mean reward 37.300, speed 134.39 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "72055: done 2491 episodes, mean reward 37.340, speed 131.59 f/s\n",
            "72202: done 2495 episodes, mean reward 37.340, speed 136.73 f/s\n",
            "72351: done 2499 episodes, mean reward 37.310, speed 139.42 f/s\n",
            "72502: done 2503 episodes, mean reward 37.330, speed 113.68 f/s\n",
            "72614: done 2506 episodes, mean reward 37.330, speed 108.91 f/s\n",
            "72761: done 2510 episodes, mean reward 37.320, speed 110.96 f/s\n",
            "72873: done 2513 episodes, mean reward 37.330, speed 108.16 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "73022: done 2517 episodes, mean reward 37.310, speed 118.72 f/s\n",
            "73172: done 2521 episodes, mean reward 37.330, speed 136.74 f/s\n",
            "73321: done 2525 episodes, mean reward 37.360, speed 135.88 f/s\n",
            "73469: done 2529 episodes, mean reward 37.310, speed 138.34 f/s\n",
            "73621: done 2533 episodes, mean reward 37.330, speed 137.18 f/s\n",
            "73772: done 2537 episodes, mean reward 37.360, speed 135.65 f/s\n",
            "73918: done 2541 episodes, mean reward 37.330, speed 137.78 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "74071: done 2545 episodes, mean reward 37.350, speed 128.76 f/s\n",
            "74225: done 2549 episodes, mean reward 37.390, speed 134.97 f/s\n",
            "74372: done 2553 episodes, mean reward 37.370, speed 112.40 f/s\n",
            "74519: done 2557 episodes, mean reward 37.360, speed 111.21 f/s\n",
            "74628: done 2560 episodes, mean reward 37.310, speed 106.63 f/s\n",
            "74740: done 2563 episodes, mean reward 37.310, speed 110.38 f/s\n",
            "74888: done 2567 episodes, mean reward 37.280, speed 121.18 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "75035: done 2571 episodes, mean reward 37.240, speed 130.80 f/s\n",
            "75185: done 2575 episodes, mean reward 37.250, speed 137.98 f/s\n",
            "75339: done 2579 episodes, mean reward 37.280, speed 133.94 f/s\n",
            "75492: done 2583 episodes, mean reward 37.330, speed 137.93 f/s\n",
            "75642: done 2587 episodes, mean reward 37.380, speed 134.77 f/s\n",
            "75789: done 2591 episodes, mean reward 37.340, speed 135.47 f/s\n",
            "75937: done 2595 episodes, mean reward 37.350, speed 137.91 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "76084: done 2599 episodes, mean reward 37.330, speed 131.48 f/s\n",
            "76233: done 2603 episodes, mean reward 37.310, speed 118.89 f/s\n",
            "76345: done 2606 episodes, mean reward 37.310, speed 109.29 f/s\n",
            "76453: done 2609 episodes, mean reward 37.280, speed 105.64 f/s\n",
            "76564: done 2612 episodes, mean reward 37.290, speed 108.81 f/s\n",
            "76675: done 2615 episodes, mean reward 37.280, speed 110.24 f/s\n",
            "76824: done 2619 episodes, mean reward 37.280, speed 130.93 f/s\n",
            "76973: done 2623 episodes, mean reward 37.260, speed 138.51 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "77118: done 2627 episodes, mean reward 37.240, speed 132.24 f/s\n",
            "77267: done 2631 episodes, mean reward 37.220, speed 136.50 f/s\n",
            "77418: done 2635 episodes, mean reward 37.200, speed 137.98 f/s\n",
            "77565: done 2639 episodes, mean reward 37.200, speed 138.03 f/s\n",
            "77715: done 2643 episodes, mean reward 37.210, speed 136.52 f/s\n",
            "77868: done 2647 episodes, mean reward 37.210, speed 137.29 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "78018: done 2651 episodes, mean reward 37.190, speed 130.87 f/s\n",
            "78169: done 2655 episodes, mean reward 37.250, speed 114.68 f/s\n",
            "78282: done 2658 episodes, mean reward 37.260, speed 107.53 f/s\n",
            "78396: done 2661 episodes, mean reward 37.320, speed 109.37 f/s\n",
            "78506: done 2664 episodes, mean reward 37.300, speed 108.50 f/s\n",
            "78656: done 2668 episodes, mean reward 37.320, speed 118.85 f/s\n",
            "78805: done 2672 episodes, mean reward 37.320, speed 136.80 f/s\n",
            "78954: done 2676 episodes, mean reward 37.300, speed 137.27 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "79100: done 2680 episodes, mean reward 37.220, speed 129.30 f/s\n",
            "79250: done 2684 episodes, mean reward 37.200, speed 133.52 f/s\n",
            "79398: done 2688 episodes, mean reward 37.190, speed 139.47 f/s\n",
            "79543: done 2692 episodes, mean reward 37.170, speed 135.65 f/s\n",
            "79690: done 2696 episodes, mean reward 37.160, speed 132.43 f/s\n",
            "79842: done 2700 episodes, mean reward 37.210, speed 134.85 f/s\n",
            "79991: done 2704 episodes, mean reward 37.210, speed 122.28 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "80105: done 2707 episodes, mean reward 37.240, speed 104.64 f/s\n",
            "80221: done 2710 episodes, mean reward 37.310, speed 105.00 f/s\n",
            "80334: done 2713 episodes, mean reward 37.330, speed 107.93 f/s\n",
            "80449: done 2716 episodes, mean reward 37.370, speed 111.25 f/s\n",
            "80599: done 2720 episodes, mean reward 37.380, speed 128.19 f/s\n",
            "80750: done 2724 episodes, mean reward 37.410, speed 135.81 f/s\n",
            "80902: done 2728 episodes, mean reward 37.470, speed 136.97 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "81050: done 2732 episodes, mean reward 37.450, speed 131.05 f/s\n",
            "81201: done 2736 episodes, mean reward 37.460, speed 135.42 f/s\n",
            "81355: done 2740 episodes, mean reward 37.520, speed 134.61 f/s\n",
            "81506: done 2744 episodes, mean reward 37.540, speed 134.19 f/s\n",
            "81655: done 2748 episodes, mean reward 37.500, speed 135.66 f/s\n",
            "81809: done 2752 episodes, mean reward 37.520, speed 136.05 f/s\n",
            "81923: done 2755 episodes, mean reward 37.540, speed 109.11 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "82040: done 2758 episodes, mean reward 37.580, speed 102.76 f/s\n",
            "82154: done 2761 episodes, mean reward 37.580, speed 108.75 f/s\n",
            "82269: done 2764 episodes, mean reward 37.630, speed 104.73 f/s\n",
            "82387: done 2767 episodes, mean reward 37.690, speed 113.64 f/s\n",
            "82545: done 2771 episodes, mean reward 37.780, speed 135.50 f/s\n",
            "82706: done 2775 episodes, mean reward 37.880, speed 137.90 f/s\n",
            "82862: done 2779 episodes, mean reward 37.980, speed 139.17 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "83014: done 2783 episodes, mean reward 38.000, speed 129.52 f/s\n",
            "83171: done 2787 episodes, mean reward 38.090, speed 138.61 f/s\n",
            "83327: done 2791 episodes, mean reward 38.190, speed 138.96 f/s\n",
            "83483: done 2795 episodes, mean reward 38.310, speed 138.01 f/s\n",
            "83637: done 2799 episodes, mean reward 38.350, speed 139.56 f/s\n",
            "83790: done 2803 episodes, mean reward 38.380, speed 119.19 f/s\n",
            "83908: done 2806 episodes, mean reward 38.420, speed 111.39 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "84026: done 2809 episodes, mean reward 38.430, speed 102.91 f/s\n",
            "84140: done 2812 episodes, mean reward 38.450, speed 106.98 f/s\n",
            "84257: done 2815 episodes, mean reward 38.470, speed 113.35 f/s\n",
            "84414: done 2819 episodes, mean reward 38.530, speed 136.87 f/s\n",
            "84573: done 2823 episodes, mean reward 38.610, speed 139.41 f/s\n",
            "84729: done 2827 episodes, mean reward 38.660, speed 137.82 f/s\n",
            "84881: done 2831 episodes, mean reward 38.670, speed 135.86 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "85036: done 2835 episodes, mean reward 38.730, speed 128.91 f/s\n",
            "85191: done 2839 episodes, mean reward 38.760, speed 137.96 f/s\n",
            "85347: done 2843 episodes, mean reward 38.790, speed 137.22 f/s\n",
            "85508: done 2847 episodes, mean reward 38.900, speed 140.51 f/s\n",
            "85664: done 2851 episodes, mean reward 38.940, speed 125.63 f/s\n",
            "85778: done 2854 episodes, mean reward 38.930, speed 111.91 f/s\n",
            "85894: done 2857 episodes, mean reward 38.930, speed 108.02 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "86008: done 2860 episodes, mean reward 38.910, speed 102.92 f/s\n",
            "86122: done 2863 episodes, mean reward 38.920, speed 107.52 f/s\n",
            "86277: done 2867 episodes, mean reward 38.900, speed 133.41 f/s\n",
            "86437: done 2871 episodes, mean reward 38.920, speed 137.31 f/s\n",
            "86594: done 2875 episodes, mean reward 38.880, speed 137.11 f/s\n",
            "86754: done 2879 episodes, mean reward 38.920, speed 137.87 f/s\n",
            "86912: done 2883 episodes, mean reward 38.980, speed 132.57 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "87068: done 2887 episodes, mean reward 38.970, speed 133.42 f/s\n",
            "87223: done 2891 episodes, mean reward 38.960, speed 138.99 f/s\n",
            "87381: done 2895 episodes, mean reward 38.980, speed 138.23 f/s\n",
            "87538: done 2899 episodes, mean reward 39.010, speed 126.34 f/s\n",
            "87681: done 2903 episodes, mean reward 38.910, speed 107.34 f/s\n",
            "87826: done 2907 episodes, mean reward 38.790, speed 110.02 f/s\n",
            "87971: done 2911 episodes, mean reward 38.690, speed 108.67 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "88087: done 2914 episodes, mean reward 38.690, speed 111.43 f/s\n",
            "88239: done 2918 episodes, mean reward 38.640, speed 137.12 f/s\n",
            "88394: done 2922 episodes, mean reward 38.610, speed 135.72 f/s\n",
            "88548: done 2926 episodes, mean reward 38.570, speed 135.75 f/s\n",
            "88704: done 2930 episodes, mean reward 38.610, speed 134.72 f/s\n",
            "88857: done 2934 episodes, mean reward 38.600, speed 134.21 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "89010: done 2938 episodes, mean reward 38.580, speed 128.08 f/s\n",
            "89165: done 2942 episodes, mean reward 38.560, speed 130.37 f/s\n",
            "89323: done 2946 episodes, mean reward 38.560, speed 139.01 f/s\n",
            "89479: done 2950 episodes, mean reward 38.540, speed 116.50 f/s\n",
            "89599: done 2953 episodes, mean reward 38.590, speed 111.50 f/s\n",
            "89712: done 2956 episodes, mean reward 38.560, speed 106.10 f/s\n",
            "89830: done 2959 episodes, mean reward 38.600, speed 108.22 f/s\n",
            "89950: done 2962 episodes, mean reward 38.650, speed 114.63 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "90090: done 2966 episodes, mean reward 38.530, speed 128.23 f/s\n",
            "90246: done 2970 episodes, mean reward 38.480, speed 135.06 f/s\n",
            "90403: done 2974 episodes, mean reward 38.500, speed 136.75 f/s\n",
            "90553: done 2978 episodes, mean reward 38.400, speed 135.81 f/s\n",
            "90713: done 2982 episodes, mean reward 38.420, speed 134.93 f/s\n",
            "90865: done 2986 episodes, mean reward 38.350, speed 136.45 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "91019: done 2990 episodes, mean reward 38.340, speed 134.05 f/s\n",
            "91175: done 2994 episodes, mean reward 38.340, speed 137.96 f/s\n",
            "91329: done 2998 episodes, mean reward 38.310, speed 119.68 f/s\n",
            "91445: done 3001 episodes, mean reward 38.330, speed 111.48 f/s\n",
            "91560: done 3004 episodes, mean reward 38.390, speed 107.80 f/s\n",
            "91700: done 3008 episodes, mean reward 38.340, speed 108.33 f/s\n",
            "91848: done 3012 episodes, mean reward 38.380, speed 115.76 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "92002: done 3016 episodes, mean reward 38.390, speed 132.30 f/s\n",
            "92156: done 3020 episodes, mean reward 38.400, speed 137.44 f/s\n",
            "92314: done 3024 episodes, mean reward 38.430, speed 138.09 f/s\n",
            "92470: done 3028 episodes, mean reward 38.450, speed 138.05 f/s\n",
            "92623: done 3032 episodes, mean reward 38.410, speed 138.18 f/s\n",
            "92778: done 3036 episodes, mean reward 38.430, speed 140.42 f/s\n",
            "92935: done 3040 episodes, mean reward 38.470, speed 136.74 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "93091: done 3044 episodes, mean reward 38.460, speed 130.17 f/s\n",
            "93248: done 3048 episodes, mean reward 38.480, speed 115.22 f/s\n",
            "93363: done 3051 episodes, mean reward 38.440, speed 109.97 f/s\n",
            "93481: done 3054 episodes, mean reward 38.480, speed 111.06 f/s\n",
            "93599: done 3057 episodes, mean reward 38.470, speed 110.96 f/s\n",
            "93718: done 3060 episodes, mean reward 38.480, speed 113.28 f/s\n",
            "93878: done 3064 episodes, mean reward 38.610, speed 135.87 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "94035: done 3068 episodes, mean reward 38.670, speed 131.22 f/s\n",
            "94189: done 3072 episodes, mean reward 38.640, speed 133.47 f/s\n",
            "94345: done 3076 episodes, mean reward 38.740, speed 136.64 f/s\n",
            "94500: done 3080 episodes, mean reward 38.660, speed 133.41 f/s\n",
            "94617: done 3083 episodes, mean reward 38.670, speed 115.86 f/s\n",
            "94771: done 3087 episodes, mean reward 38.670, speed 133.88 f/s\n",
            "94929: done 3091 episodes, mean reward 38.730, speed 136.52 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "95051: done 3094 episodes, mean reward 38.760, speed 116.01 f/s\n",
            "95171: done 3097 episodes, mean reward 38.810, speed 109.06 f/s\n",
            "95291: done 3100 episodes, mean reward 38.860, speed 109.93 f/s\n",
            "95409: done 3103 episodes, mean reward 38.880, speed 108.51 f/s\n",
            "95526: done 3106 episodes, mean reward 38.920, speed 104.94 f/s\n",
            "95677: done 3110 episodes, mean reward 39.090, speed 130.18 f/s\n",
            "95832: done 3114 episodes, mean reward 39.080, speed 136.17 f/s\n",
            "95991: done 3118 episodes, mean reward 39.120, speed 137.65 f/s\n",
            "Test done in 0.04 sec, reward 8.000, steps 8\n",
            "96149: done 3122 episodes, mean reward 39.150, speed 133.08 f/s\n",
            "96306: done 3126 episodes, mean reward 39.130, speed 136.61 f/s\n",
            "96465: done 3130 episodes, mean reward 39.180, speed 138.36 f/s\n",
            "96622: done 3134 episodes, mean reward 39.230, speed 137.44 f/s\n",
            "96777: done 3138 episodes, mean reward 39.200, speed 135.77 f/s\n",
            "96931: done 3142 episodes, mean reward 39.190, speed 127.96 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "97046: done 3145 episodes, mean reward 39.160, speed 103.53 f/s\n",
            "97164: done 3148 episodes, mean reward 39.160, speed 110.77 f/s\n",
            "97280: done 3151 episodes, mean reward 39.170, speed 109.74 f/s\n",
            "97394: done 3154 episodes, mean reward 39.130, speed 105.86 f/s\n",
            "97549: done 3158 episodes, mean reward 39.110, speed 128.11 f/s\n",
            "97710: done 3162 episodes, mean reward 39.120, speed 138.05 f/s\n",
            "97865: done 3166 episodes, mean reward 39.080, speed 139.63 f/s\n",
            "Test done in 0.05 sec, reward 8.000, steps 8\n",
            "98023: done 3170 episodes, mean reward 39.110, speed 132.16 f/s\n",
            "98181: done 3174 episodes, mean reward 39.140, speed 137.16 f/s\n",
            "98341: done 3178 episodes, mean reward 39.180, speed 135.72 f/s\n",
            "98504: done 3182 episodes, mean reward 39.260, speed 137.43 f/s\n",
            "98660: done 3186 episodes, mean reward 39.280, speed 135.18 f/s\n",
            "98821: done 3190 episodes, mean reward 39.330, speed 130.60 f/s\n",
            "98938: done 3193 episodes, mean reward 39.280, speed 107.83 f/s\n",
            "Test done in 0.06 sec, reward 8.000, steps 8\n",
            "99057: done 3196 episodes, mean reward 39.260, speed 103.07 f/s\n",
            "99174: done 3199 episodes, mean reward 39.240, speed 111.70 f/s\n",
            "99294: done 3202 episodes, mean reward 39.240, speed 109.77 f/s\n",
            "99452: done 3206 episodes, mean reward 39.260, speed 124.18 f/s\n",
            "99610: done 3210 episodes, mean reward 39.330, speed 138.50 f/s\n",
            "99765: done 3214 episodes, mean reward 39.330, speed 136.65 f/s\n",
            "99918: done 3218 episodes, mean reward 39.270, speed 135.04 f/s\n",
            "Test done in 0.08 sec, reward 15.200, steps 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(recompensas_ent)\n",
        "plt.xlabel('Cada '+ str(TEST_ITERS)+' pasos')\n",
        "plt.ylabel('Recompensa')\n",
        "plt.legend('Gráfico')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GRitKYGsJKDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "e7654128-d36c-407d-d20e-40be89be015e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}