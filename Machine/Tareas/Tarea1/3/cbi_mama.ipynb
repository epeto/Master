{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036b60b9",
   "metadata": {},
   "source": [
    "# Predicción de cáncer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b83183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import random\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fdf87",
   "metadata": {},
   "source": [
    "Se puede hacer una \"limpieza\" de los datos, antes de procesarlos. Esto es porque la primera columna no es importante para las predicciones, ya que solo representa un ID de una muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa755e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacsv = pandas.read_csv('breast-cancer-wisconsin.csv')\n",
    "datanp = datacsv.to_numpy()\n",
    "#No todos los datos se conviertieron a números, así que lo haré a mano.\n",
    "for i in range(datanp.shape[0]):\n",
    "    for j in range(datanp.shape[1]):\n",
    "        if datanp[i][j] == '?':\n",
    "            datanp[i][j] = -1\n",
    "        else:\n",
    "            datanp[i][j] = int(datanp[i][j])\n",
    "#Se borra la primera columna\n",
    "datanp = numpy.array(list(map(lambda x : x[1:len(x)], datanp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdfac9",
   "metadata": {},
   "source": [
    "Se parte el conjunto de datos en 3: el de entrenamiento, el de validación y el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9569b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte al conjunto de datos en 3, de forma aleatoria.\n",
    "# Cada parámetro (entrenamiento, validación y prueba) es una fracción del tamaño del\n",
    "# subconjunto de datos entre el tamaño del conjunto total.\n",
    "def particion(datos, entrenamiento, validacion, prueba):\n",
    "    n = datos.shape[0]\n",
    "    indices_total = [i for i in range(n)]\n",
    "    indices_ent = []\n",
    "    random.seed(0) #Se usa 0 como semilla\n",
    "    while (len(indices_ent)/n) < entrenamiento:\n",
    "        indice_rand = random.randint(0, len(indices_total)-1)\n",
    "        indices_ent.append(indices_total[indice_rand])\n",
    "        del indices_total[indice_rand]\n",
    "    indices_val = []\n",
    "    while (len(indices_val)/n) < validacion:\n",
    "        indice_rand = random.randint(0, len(indices_total)-1)\n",
    "        indices_val.append(indices_total[indice_rand])\n",
    "        del indices_total[indice_rand]\n",
    "    #En este punto, indices_total tendrá los índices para validación\n",
    "    datos_ent = []\n",
    "    datos_val = []\n",
    "    datos_pru = []\n",
    "    for i in indices_ent:\n",
    "        datos_ent.append(datos[i])\n",
    "    for i in indices_val:\n",
    "        datos_val.append(datos[i])\n",
    "    for i in indices_total:\n",
    "        datos_pru.append(datos[i])\n",
    "    return (numpy.array(datos_ent), numpy.array(datos_val), numpy.array(datos_pru))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b1a6d",
   "metadata": {},
   "source": [
    "Para rellenar los espacios donde hay atributos no especificados (donde aparece ?), se usará el promedio del resto. En este caso, yo cambié el '?' por -1 para que todos los datos fueran numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb365ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifica_columna(matriz, columna):\n",
    "    suma = 0\n",
    "    filas_m1 = []\n",
    "    for i in range(matriz.shape[0]):\n",
    "        if matriz[i][columna] != -1:\n",
    "            suma += matriz[i][columna]\n",
    "        else:\n",
    "            filas_m1.append(i)\n",
    "    promedio = suma/matriz.shape[0]\n",
    "    promedio = math.floor(promedio)\n",
    "    for fila in filas_m1:\n",
    "        matriz[fila][columna] = promedio\n",
    "\n",
    "# ya sabemos que la columna que contiene -1 es la 5.\n",
    "modifica_columna(datanp, 5)\n",
    "# Ahora sí, se parte al conjunto en 3\n",
    "data_ent, data_val, data_pru = particion(datanp, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f91e8",
   "metadata": {},
   "source": [
    "## Clasificador con distribución gausiana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d64181",
   "metadata": {},
   "source": [
    "El primer modelo a entrenar será el que tenga distribución gausiana y para esto se usarán las bibliotecas de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57adb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma un arreglo (unidimensional o bidimensional) a una lista\n",
    "def numpy_a_list(arreglo):\n",
    "    dimens = len(arreglo.shape)\n",
    "    if dimens == 1:\n",
    "        lista = []\n",
    "        for i in range(arreglo.shape[0]):\n",
    "            lista.append(arreglo[i])\n",
    "        return lista\n",
    "    else:\n",
    "        matriz = []\n",
    "        for i in range(arreglo.shape[0]):\n",
    "            vector = []\n",
    "            for j in range(arreglo.shape[1]):\n",
    "                vector.append(arreglo[i][j])\n",
    "            matriz.append(vector)\n",
    "        return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142dfa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve la razón de los aciertos entre los totales.\n",
    "def frac_aciertos(prediccion, real):\n",
    "    aciertos = 0\n",
    "    for i in range(len(prediccion)):\n",
    "        if prediccion[i] == real[i]:\n",
    "            aciertos += 1\n",
    "    return (aciertos/len(prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43ffe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud con datos de entrenamiento: 95.71428571428572%\n",
      "Exactitud con datos de validación: 96.42857142857143%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "# Primero con los datos de entrenamiento\n",
    "X_ent = data_ent[:, :-1]\n",
    "y_ent = data_ent[:, -1]\n",
    "X_ent_list = numpy_a_list(X_ent)\n",
    "y_ent_list = numpy_a_list(y_ent)\n",
    "gnb.fit(X_ent_list, y_ent_list)\n",
    "ypge = gnb.predict(X_ent)\n",
    "fae_gaus = frac_aciertos(ypge, y_ent_list)\n",
    "# Luego con los datos de validación\n",
    "X_val = data_val[:, : -1]\n",
    "y_val = data_val[:, -1]\n",
    "ypgv = gnb.predict(X_val)\n",
    "fav_gaus = frac_aciertos(ypgv, y_val)\n",
    "print(\"Exactitud con datos de entrenamiento:\", str(fae_gaus*100)+'%')\n",
    "print(\"Exactitud con datos de validación:\", str(fav_gaus*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa6b0b",
   "metadata": {},
   "source": [
    "## Clasificador con distribución multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62cac0",
   "metadata": {},
   "source": [
    "Ahora se harán las predicciones con distribución multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533b86b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud con datos de entrenamiento: 88.57142857142857%\n",
      "Exactitud con datos de validación: 90.0%\n"
     ]
    }
   ],
   "source": [
    "# Predicción con los datos de entrenamiento\n",
    "multinb = MultinomialNB()\n",
    "multinb.fit(X_ent_list, y_ent_list)\n",
    "ypme = multinb.predict(X_ent)\n",
    "fae_mult = frac_aciertos(ypme, y_ent)\n",
    "# Predicción con los datos de validación\n",
    "ypmv = multinb.predict(X_val)\n",
    "fav_mult = frac_aciertos(ypmv, y_val)\n",
    "print(\"Exactitud con datos de entrenamiento:\", str(fae_mult*100)+'%')\n",
    "print(\"Exactitud con datos de validación:\", str(fav_mult*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2fc51",
   "metadata": {},
   "source": [
    "Con esto se observa que la distribución gausiana tiene mayor exactitud. Ahora se comprobará su efectividad en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf56a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en los datos de prueba: 96.40287769784173%\n"
     ]
    }
   ],
   "source": [
    "X_pru = data_pru[:, :-1]\n",
    "y_pru = data_pru[:, -1]\n",
    "ypgp = gnb.predict(X_pru)\n",
    "fap_gaus = frac_aciertos(ypgp, y_pru)\n",
    "print(\"Exactitud en los datos de prueba:\",str(fap_gaus*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13249ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
